{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4f31ea9",
   "metadata": {},
   "source": [
    "<h1>Statistics, graph measures and SVM classification</h1>\n",
    "\n",
    "This notebook includes the main analysis of our data, after the preprocessing phase, and we will base our discussion on the results obtained here. The analysis phase can be summarized this way: first we derive a number of graph measures, both global and nodal, from our data, and we test whether there are statistically significant differences between groups regarding those graph measures. Only those measures that will deliver a statistically significant difference between groups will be used for the classification tasks.  We will be focusing mostly on testing differences between patients and controls, but we also check for possible differences between disease phenotype groups (RRMS vs. PPMS/SPMS). Because of the high amount of comparisons in each test, rather than implementing a Bonferroni correction for each test we have decided to use p<0.001 as a threshold to determine whether a graph measure is subsequently used for the classification task.\n",
    "\n",
    "Next, we will execute several classification tasks, using Support Vector Machine (SVM). There will be three types of classification:\n",
    "\n",
    "-Using our connectivity data (structural, functional and weighted combined)\n",
    "\n",
    "-Using graph measures (global and nodal)\n",
    "\n",
    "-Using brain volumes\n",
    "\n",
    "We will also do here some further processing of the stregth graph measures that we will use for our visualizations.  \n",
    "\n",
    "\n",
    "---------------\n",
    "\n",
    "Index for the notebook:\n",
    "\n",
    "- [1. Data loading](#a1)\n",
    "- [2. Graph measures first try](#a2)\n",
    "- [3. Functions for graph measures](#a3)\n",
    "- [4. Graph measures](#a4)  \n",
    "  * [4.1 Strength](#a4.1)  \n",
    "  * [4.2 Node Degree](#a4.2)  \n",
    "  * [4.3 Degree Centrality](#a4.3)  \n",
    "  * [4.4 Closeness centrality](#a4.4)  \n",
    "  * [4.5 Clustering coefficient](#a4.5)  \n",
    "  * [4.6 Local Efficiency](#a4.6)  \n",
    "  * [4.7 Global efficiency](#a4.7)  \n",
    "  * [4.8 Betweenness Centrality](#a4.8)  \n",
    "  * [4.9 Eigenvector Centrality](#a4.9)  \n",
    "  * [4.10 Assortativity](#a4.10)  \n",
    "  * [4.11 Rich Club](#a4.11)  \n",
    "    + [4.11.1 Results](#a4.11.1)  \n",
    "- [5. Classification](#a5)  \n",
    "  * [5.1 Functions for FA classification](#a5.1)  \n",
    "  * [5.2 Connectivity based classification](#a5.2)    \n",
    "    + [5.2.1 Results](#a5.2.1)  \n",
    "  * [5.3 Functions for graph based classification](#a5.3)  \n",
    "  * [5.4 Classification using global graph measures](#a5.4)  \n",
    "  * [5.5 Classification using vectors of diverse nodal graph measures](#a5.5)  \n",
    "    + [5.5.1 Results](#a5.5.1)  \n",
    "  * [5.6 Classification using brain volumes](#a5.6)  \n",
    "    + [5.6.1 All brain volumes](#a5.6.1)  \n",
    "    + [5.6.2 Thalamic volumes](#a5.6.2)  \n",
    "    + [5.6.3 Five most different volumes](#a5.6.3)  \n",
    "    + [5.6.4 Results](#a5.6.4)  \n",
    "  * [5.7 Summary of classification results](#a5.7)  \n",
    "- [6. Comparison of strength for connectogram visualization](#a6)\n",
    "- [7. Preliminary conclusions](#a7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff04ce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import os.path\n",
    "\n",
    "from statistics import mean, median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e500cd",
   "metadata": {},
   "source": [
    "<a id='a1'></a>\n",
    "<h1>Data Loading</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ce47489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load the preprocessed data and we separate patients from controls\n",
    "\n",
    "path_st = 'structural_ready'\n",
    "path_func = 'functional_ready'\n",
    "\n",
    "csv_files_st = [file for file in sorted(os.listdir(path_st), key=lambda x: x.lower())]\n",
    "csv_files_func = [file for file in sorted(os.listdir(path_func), key=lambda x: x.lower())]\n",
    "\n",
    "st_matrices = [pd.read_csv(os.path.join(path_st, file), header=None) for file in csv_files_st]\n",
    "func_matrices = [pd.read_csv(os.path.join(path_func, file), header=None) for file in csv_files_func]\n",
    "\n",
    "demographics_df = pd.read_csv('clinic.csv')\n",
    "labels = list(demographics_df['controls_ms'])\n",
    "ms_type = list(demographics_df['mstype'])\n",
    "\n",
    "ms_st = [st_matrices[i] for i, value in enumerate(labels) if value == 1]\n",
    "hv_st = [st_matrices[i] for i, value in enumerate(labels) if value == 0]\n",
    "\n",
    "ms_func = [func_matrices[i] for i, value in enumerate(labels) if value == 1]\n",
    "hv_func = [func_matrices[i] for i, value in enumerate(labels) if value == 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46041e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the brain volume data\n",
    "\n",
    "volumes_patients = pd.read_csv('volum_nodes_patients.csv') \n",
    "volumes_controls = pd.read_csv('volum_nodes_controls.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5f5e7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002MSVIS</td>\n",
       "      <td>3672</td>\n",
       "      <td>7928</td>\n",
       "      <td>5064</td>\n",
       "      <td>3864</td>\n",
       "      <td>11512</td>\n",
       "      <td>14088</td>\n",
       "      <td>13424</td>\n",
       "      <td>2872</td>\n",
       "      <td>13240</td>\n",
       "      <td>...</td>\n",
       "      <td>13696</td>\n",
       "      <td>12888</td>\n",
       "      <td>2872</td>\n",
       "      <td>12704</td>\n",
       "      <td>31088</td>\n",
       "      <td>11536</td>\n",
       "      <td>16560</td>\n",
       "      <td>8784</td>\n",
       "      <td>848</td>\n",
       "      <td>7600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>003MSVIS</td>\n",
       "      <td>4040</td>\n",
       "      <td>8544</td>\n",
       "      <td>4144</td>\n",
       "      <td>3208</td>\n",
       "      <td>12872</td>\n",
       "      <td>16688</td>\n",
       "      <td>13288</td>\n",
       "      <td>2736</td>\n",
       "      <td>14840</td>\n",
       "      <td>...</td>\n",
       "      <td>16176</td>\n",
       "      <td>11592</td>\n",
       "      <td>2808</td>\n",
       "      <td>13864</td>\n",
       "      <td>34160</td>\n",
       "      <td>14384</td>\n",
       "      <td>19168</td>\n",
       "      <td>13232</td>\n",
       "      <td>1312</td>\n",
       "      <td>7904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004MSVIS</td>\n",
       "      <td>5224</td>\n",
       "      <td>7656</td>\n",
       "      <td>4136</td>\n",
       "      <td>3192</td>\n",
       "      <td>11712</td>\n",
       "      <td>15728</td>\n",
       "      <td>14720</td>\n",
       "      <td>3960</td>\n",
       "      <td>13368</td>\n",
       "      <td>...</td>\n",
       "      <td>13696</td>\n",
       "      <td>11760</td>\n",
       "      <td>3304</td>\n",
       "      <td>14024</td>\n",
       "      <td>29896</td>\n",
       "      <td>12328</td>\n",
       "      <td>18824</td>\n",
       "      <td>12240</td>\n",
       "      <td>1304</td>\n",
       "      <td>7856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005MSVIS</td>\n",
       "      <td>4664</td>\n",
       "      <td>9064</td>\n",
       "      <td>4848</td>\n",
       "      <td>3520</td>\n",
       "      <td>13512</td>\n",
       "      <td>17696</td>\n",
       "      <td>14712</td>\n",
       "      <td>3960</td>\n",
       "      <td>13800</td>\n",
       "      <td>...</td>\n",
       "      <td>16216</td>\n",
       "      <td>13928</td>\n",
       "      <td>3000</td>\n",
       "      <td>14776</td>\n",
       "      <td>33904</td>\n",
       "      <td>12744</td>\n",
       "      <td>21024</td>\n",
       "      <td>11904</td>\n",
       "      <td>1576</td>\n",
       "      <td>10240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>010MSVIS</td>\n",
       "      <td>5520</td>\n",
       "      <td>9056</td>\n",
       "      <td>4560</td>\n",
       "      <td>3560</td>\n",
       "      <td>12856</td>\n",
       "      <td>17048</td>\n",
       "      <td>14264</td>\n",
       "      <td>3848</td>\n",
       "      <td>13720</td>\n",
       "      <td>...</td>\n",
       "      <td>14696</td>\n",
       "      <td>12544</td>\n",
       "      <td>3656</td>\n",
       "      <td>14440</td>\n",
       "      <td>35600</td>\n",
       "      <td>12824</td>\n",
       "      <td>21200</td>\n",
       "      <td>13976</td>\n",
       "      <td>1608</td>\n",
       "      <td>9096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>FIS_125</td>\n",
       "      <td>4456</td>\n",
       "      <td>8024</td>\n",
       "      <td>4408</td>\n",
       "      <td>3248</td>\n",
       "      <td>11744</td>\n",
       "      <td>16208</td>\n",
       "      <td>12800</td>\n",
       "      <td>3160</td>\n",
       "      <td>15304</td>\n",
       "      <td>...</td>\n",
       "      <td>13632</td>\n",
       "      <td>14624</td>\n",
       "      <td>3280</td>\n",
       "      <td>15440</td>\n",
       "      <td>34304</td>\n",
       "      <td>13008</td>\n",
       "      <td>18112</td>\n",
       "      <td>13392</td>\n",
       "      <td>1320</td>\n",
       "      <td>8296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>FIS_126</td>\n",
       "      <td>4240</td>\n",
       "      <td>7904</td>\n",
       "      <td>4784</td>\n",
       "      <td>3080</td>\n",
       "      <td>12168</td>\n",
       "      <td>16088</td>\n",
       "      <td>14504</td>\n",
       "      <td>3336</td>\n",
       "      <td>13016</td>\n",
       "      <td>...</td>\n",
       "      <td>11784</td>\n",
       "      <td>12224</td>\n",
       "      <td>2432</td>\n",
       "      <td>12200</td>\n",
       "      <td>30408</td>\n",
       "      <td>11592</td>\n",
       "      <td>16376</td>\n",
       "      <td>11464</td>\n",
       "      <td>1288</td>\n",
       "      <td>8496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>FIS_127</td>\n",
       "      <td>5296</td>\n",
       "      <td>9336</td>\n",
       "      <td>5064</td>\n",
       "      <td>3040</td>\n",
       "      <td>14488</td>\n",
       "      <td>18008</td>\n",
       "      <td>14432</td>\n",
       "      <td>4352</td>\n",
       "      <td>16080</td>\n",
       "      <td>...</td>\n",
       "      <td>16016</td>\n",
       "      <td>13288</td>\n",
       "      <td>3824</td>\n",
       "      <td>14944</td>\n",
       "      <td>39072</td>\n",
       "      <td>13288</td>\n",
       "      <td>20936</td>\n",
       "      <td>14240</td>\n",
       "      <td>1568</td>\n",
       "      <td>9312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>FIS_128</td>\n",
       "      <td>4464</td>\n",
       "      <td>8048</td>\n",
       "      <td>4768</td>\n",
       "      <td>3216</td>\n",
       "      <td>13568</td>\n",
       "      <td>17120</td>\n",
       "      <td>14072</td>\n",
       "      <td>3608</td>\n",
       "      <td>17840</td>\n",
       "      <td>...</td>\n",
       "      <td>15312</td>\n",
       "      <td>13368</td>\n",
       "      <td>3856</td>\n",
       "      <td>13360</td>\n",
       "      <td>38984</td>\n",
       "      <td>14296</td>\n",
       "      <td>20208</td>\n",
       "      <td>12200</td>\n",
       "      <td>1752</td>\n",
       "      <td>8568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>FIS_129</td>\n",
       "      <td>3616</td>\n",
       "      <td>5728</td>\n",
       "      <td>4816</td>\n",
       "      <td>3384</td>\n",
       "      <td>11456</td>\n",
       "      <td>14304</td>\n",
       "      <td>12312</td>\n",
       "      <td>3512</td>\n",
       "      <td>13312</td>\n",
       "      <td>...</td>\n",
       "      <td>11792</td>\n",
       "      <td>11632</td>\n",
       "      <td>2704</td>\n",
       "      <td>10512</td>\n",
       "      <td>28152</td>\n",
       "      <td>11888</td>\n",
       "      <td>13184</td>\n",
       "      <td>10216</td>\n",
       "      <td>704</td>\n",
       "      <td>8592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0     1     2     3     4      5      6      7     8      9  ...  \\\n",
       "0    002MSVIS  3672  7928  5064  3864  11512  14088  13424  2872  13240  ...   \n",
       "1    003MSVIS  4040  8544  4144  3208  12872  16688  13288  2736  14840  ...   \n",
       "2    004MSVIS  5224  7656  4136  3192  11712  15728  14720  3960  13368  ...   \n",
       "3    005MSVIS  4664  9064  4848  3520  13512  17696  14712  3960  13800  ...   \n",
       "4    010MSVIS  5520  9056  4560  3560  12856  17048  14264  3848  13720  ...   \n",
       "..        ...   ...   ...   ...   ...    ...    ...    ...   ...    ...  ...   \n",
       "142   FIS_125  4456  8024  4408  3248  11744  16208  12800  3160  15304  ...   \n",
       "143   FIS_126  4240  7904  4784  3080  12168  16088  14504  3336  13016  ...   \n",
       "144   FIS_127  5296  9336  5064  3040  14488  18008  14432  4352  16080  ...   \n",
       "145   FIS_128  4464  8048  4768  3216  13568  17120  14072  3608  17840  ...   \n",
       "146   FIS_129  3616  5728  4816  3384  11456  14304  12312  3512  13312  ...   \n",
       "\n",
       "        67     68    69     70     71     72     73     74    75     76  \n",
       "0    13696  12888  2872  12704  31088  11536  16560   8784   848   7600  \n",
       "1    16176  11592  2808  13864  34160  14384  19168  13232  1312   7904  \n",
       "2    13696  11760  3304  14024  29896  12328  18824  12240  1304   7856  \n",
       "3    16216  13928  3000  14776  33904  12744  21024  11904  1576  10240  \n",
       "4    14696  12544  3656  14440  35600  12824  21200  13976  1608   9096  \n",
       "..     ...    ...   ...    ...    ...    ...    ...    ...   ...    ...  \n",
       "142  13632  14624  3280  15440  34304  13008  18112  13392  1320   8296  \n",
       "143  11784  12224  2432  12200  30408  11592  16376  11464  1288   8496  \n",
       "144  16016  13288  3824  14944  39072  13288  20936  14240  1568   9312  \n",
       "145  15312  13368  3856  13360  38984  14296  20208  12200  1752   8568  \n",
       "146  11792  11632  2704  10512  28152  11888  13184  10216   704   8592  \n",
       "\n",
       "[147 rows x 77 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volumes_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fea03bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We convert volume matrices to lists\n",
    "\n",
    "volumes_ms = volumes_patients.values[:,1:].tolist()\n",
    "volumes_hv = volumes_controls.values[:,1:].tolist()\n",
    "volumes = volumes_ms + volumes_hv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58ba0377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# We show the patients vs. hv labels \n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e87b245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1]\n"
     ]
    }
   ],
   "source": [
    "# Here are the phenotype labels\n",
    "print(ms_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1d3f93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# We filter out hv controls from the phenotype labels\n",
    "ms_type_ms = [i for i in ms_type if i >= 0]\n",
    "print(ms_type_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd747f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# We create 2 groups out of the 3 phenotypes: rrms vs. ppms/spms and we adjust the  lables accordingly \n",
    "ms_rr = [ms_st[i] for i, value in enumerate(ms_type_ms) if value == 0]\n",
    "ms_psp = [ms_st[i] for i, value in enumerate(ms_type_ms) if value != 0]\n",
    "\n",
    "ms_rr_func = [ms_func[i] for i, value in enumerate(ms_type_ms) if value == 0]\n",
    "ms_psp_func = [ms_func[i] for i, value in enumerate(ms_type_ms) if value != 0]\n",
    "\n",
    "ms_type_labels = [1 if i != 0 else i for i in ms_type_ms]\n",
    "print(ms_type_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45d2f658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "print(len(ms_st))\n",
    "print(len(hv_st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e48132e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'ctx-lh-caudalanteriorcingulate', 2: 'ctx-lh-caudalmiddlefrontal', 3: 'ctx-lh-cuneus', 4: 'ctx-lh-entorhinal', 5: 'ctx-lh-fusiform', 6: 'ctx-lh-inferiorparietal', 7: 'ctx-lh-inferiortemporal', 8: 'ctx-lh-isthmuscingulate', 9: 'ctx-lh-lateraloccipital', 10: 'ctx-lh-lateralorbitofrontal', 11: 'ctx-lh-lingual', 12: 'ctx-lh-medialorbitofrontal', 13: 'ctx-lh-middletemporal', 14: 'ctx-lh-parahippocampal', 15: 'ctx-lh-paracentral', 16: 'ctx-lh-parsopercularis', 17: 'ctx-lh-parsorbitalis', 18: 'ctx-lh-parstriangularis', 19: 'ctx-lh-pericalcarine', 20: 'ctx-lh-postcentral', 21: 'ctx-lh-posteriorcingulate', 22: 'ctx-lh-precentral', 23: 'ctx-lh-precuneus', 24: 'ctx-lh-rostralanteriorcingulate', 25: 'ctx-lh-rostralmiddlefrontal', 26: 'ctx-lh-superiorfrontal', 27: 'ctx-lh-superiorparietal', 28: 'ctx-lh-superiortemporal', 29: 'ctx-lh-supramarginal', 30: 'ctx-lh-transversetemporal', 31: 'ctx-lh-insula', 32: 'Left-Thalamus-Proper', 33: 'Left-Caudate', 34: 'Left-Putamen', 35: 'Left-Pallidum', 36: 'Left-Hippocampus', 37: 'Left-Amygdala', 38: 'Left-Accumbens-area', 39: 'Right-Thalamus-Proper', 40: 'Right-Caudate', 41: 'Right-Putamen', 42: 'Right-Pallidum', 43: 'Right-Hippocampus', 44: 'Right-Amygdala', 45: 'Right-Accumbens-area', 46: 'ctx-rh-caudalanteriorcingulate', 47: 'ctx-rh-caudalmiddlefrontal', 48: 'ctx-rh-cuneus', 49: 'ctx-rh-entorhinal', 50: 'ctx-rh-fusiform', 51: 'ctx-rh-inferiorparietal', 52: 'ctx-rh-inferiortemporal', 53: 'ctx-rh-isthmuscingulate', 54: 'ctx-rh-lateraloccipital', 55: 'ctx-rh-lateralorbitofrontal', 56: 'ctx-rh-lingual', 57: 'ctx-rh-medialorbitofrontal', 58: 'ctx-rh-middletemporal', 59: 'ctx-rh-parahippocampal', 60: 'ctx-rh-paracentral', 61: 'ctx-rh-parsopercularis', 62: 'ctx-rh-parsorbitalis', 63: 'ctx-rh-parstriangularis', 64: 'ctx-rh-pericalcarine', 65: 'ctx-rh-postcentral', 66: 'ctx-rh-posteriorcingulate', 67: 'ctx-rh-precentral', 68: 'ctx-rh-precuneus', 69: 'ctx-rh-rostralanteriorcingulate', 70: 'ctx-rh-rostralmiddlefrontal', 71: 'ctx-rh-superiorfrontal', 72: 'ctx-rh-superiorparietal', 73: 'ctx-rh-superiortemporal', 74: 'ctx-rh-supramarginal', 75: 'ctx-rh-transversetemporal', 76: 'ctx-rh-insula'}\n"
     ]
    }
   ],
   "source": [
    "# We show a dictionary with the names of the 76 nodes\n",
    "\n",
    "nodes_csv = pd.read_csv('nodes.csv', header=None)\n",
    "nodes = nodes_csv[1].tolist()\n",
    "nodes_dict = {i+1: j for i, j in enumerate(nodes)}\n",
    "print(nodes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a017bfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a mix of structural and functional data through a simple weighted sum, giving more \n",
    "# importance to structural connections\n",
    "\n",
    "alpha = 0.75  # Weight for structural matrices\n",
    "beta = 0.25   # Weight for functional matrices\n",
    "\n",
    "all_combined = [alpha * structural + beta * functional for structural, functional in zip(st_matrices, func_matrices)]\n",
    "\n",
    "ms_combined = [alpha * structural + beta * functional for structural, functional in zip(ms_st, ms_func)]\n",
    "hv_combined = [alpha * structural + beta * functional for structural, functional in zip(hv_st, hv_func)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98c15b8",
   "metadata": {},
   "source": [
    "<a id='a2'></a>\n",
    "<h1>Graph measures (first try)</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04311551",
   "metadata": {},
   "source": [
    "For archiving purposes, we include here our first statistical test based on the stregth measures of structural  matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "732b5ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate first the strength measure of all individual graphs\n",
    "# and the we average for the groups before implementing a test of independence between groups\n",
    "\n",
    "strength_ms_st_list = []\n",
    "strength_hv_st_list = []\n",
    "\n",
    "for m in ms_st:\n",
    "    G = nx.from_pandas_adjacency(m)\n",
    "    strength = G.degree(weight='weight')\n",
    "    strengths = {node: val for (node, val) in strength}\n",
    "    strength_ms_st_list.append(strengths)\n",
    "\n",
    "for m in hv_st:\n",
    "    G = nx.from_pandas_adjacency(m)\n",
    "    strength = G.degree(weight='weight')\n",
    "    strengths = {node: val for (node, val) in strength}\n",
    "    strength_hv_st_list.append(strengths)\n",
    "    \n",
    "\n",
    "global_strength_ms_st = [np.mean(list(s.values())) for s in strength_ms_st_list]\n",
    "global_strength_hv_st = [np.mean(list(s.values())) for s in strength_hv_st_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4946784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: -4.39126274327306, p < 0.001\n",
      "mann-whitney-statistic: 393.0, p < 0.001\n"
     ]
    }
   ],
   "source": [
    "# we obtain a significant difference p<0.001\n",
    "\n",
    "t_stat, p_value = stats.ttest_ind(global_strength_ms_st, global_strength_hv_st)\n",
    "u_stat, p_value_u = stats.mannwhitneyu(global_strength_ms_st, global_strength_hv_st)\n",
    "\n",
    "if p_value < 0.001:\n",
    "    print(f\"t-statistic: {t_stat}, p < 0.001\")\n",
    "else:\n",
    "    print(f\"t-statistic: {t_stat}, p = {p_value:.3f}\")\n",
    "\n",
    "if p_value_u < 0.001:\n",
    "    print(f\"mann-whitney-statistic: {u_stat}, p < 0.001\")\n",
    "else:\n",
    "    print(f\"mann-whitney-statistic: {u_stat}, p = {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b048936",
   "metadata": {},
   "source": [
    "<a id='a3'></a>\n",
    "<h1>Functions for graph measures</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a23634",
   "metadata": {},
   "source": [
    "After this first try, we define several functions to obtain and test independence between groups using different graph measures, both global and nodal. The functions include normality tests to decide in each instance whether a t-test or a Mann-Whitney test should be performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f460d1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph measures calculation:\n",
    "\n",
    "def calculate_graph_measures(data, measure='degree', weight='weight', network='global', layer='single'):\n",
    "    measures_list = []\n",
    "    \n",
    "    for m in data:\n",
    "        if layer == 'single':\n",
    "            G = nx.from_pandas_adjacency(m)\n",
    "        elif layer == 'multilayer':\n",
    "            G = nx.from_numpy_array(m)\n",
    "        if measure == 'degree':\n",
    "            measure_result = G.degree(weight=weight)\n",
    "            measures = {node: val for (node, val) in measure_result}\n",
    "        elif measure == 'node_degree':\n",
    "            measures = sum(dict(G.degree()).values())\n",
    "        elif measure == 'degree_centrality':\n",
    "            if network == 'global':\n",
    "                measures = list(nx.degree_centrality(G).values())   \n",
    "            else:\n",
    "                measures = nx.degree_centrality(G)\n",
    "        elif measure == 'closeness_centrality':\n",
    "            if network == 'global':\n",
    "                measures = list(nx.closeness_centrality(G).values())\n",
    "            else:\n",
    "                measures = nx.closeness_centrality(G)\n",
    "        elif measure == 'average_clustering':\n",
    "            measures = nx.average_clustering(G)\n",
    "        elif measure == 'clustering':\n",
    "            measures = nx.clustering(G)\n",
    "        elif measure == 'local_efficiency':\n",
    "            measures = nx.local_efficiency(G)\n",
    "        elif measure == 'global_efficiency':\n",
    "            measures = nx.global_efficiency(G)\n",
    "        elif measure == 'betweenness_centrality':\n",
    "            if network == 'global':\n",
    "                measures = list(nx.betweenness_centrality(G).values())   \n",
    "            else:\n",
    "                measures = nx.betweenness_centrality(G)\n",
    "        elif measure == 'eigenvector_centrality':\n",
    "            if network == 'global':\n",
    "                measures = list(nx.eigenvector_centrality(G).values())   \n",
    "            else:\n",
    "                measures = nx.eigenvector_centrality(G)\n",
    "        elif measure == 'assortativity':\n",
    "            measures = nx.degree_assortativity_coefficient(G)\n",
    "        elif measure == 'rich_club':\n",
    "            measures = nx.rich_club_coefficient(G, normalized=False, seed=42)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported graph measure: {measure}\")\n",
    "        \n",
    "        measures_list.append(measures)\n",
    "    return measures_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03d53eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independence test for global measures:\n",
    "\n",
    "def stats_test(ms=ms_st, hv=hv_st, measure='degree', weight='weight', centrality='mean', network='global', \n",
    "               layer='single'):\n",
    "    ms_list = calculate_graph_measures(ms, measure=measure, weight=weight, layer=layer)\n",
    "    hv_list = calculate_graph_measures(hv, measure=measure, weight=weight, layer=layer)\n",
    "\n",
    "    if measure == 'degree' or network != 'global':\n",
    "        if centrality == 'mean':\n",
    "            global_ms = [np.mean(list(s.values())) for s in ms_list]\n",
    "            global_hv = [np.mean(list(s.values())) for s in hv_list]\n",
    "        elif centrality ==  'median':\n",
    "            global_ms = [np.median(list(s.values())) for s in ms_list]\n",
    "            global_hv = [np.median(list(s.values())) for s in hv_list]\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported centrality measure: {centrality}\")\n",
    "    elif (measure == 'node_degree' or\n",
    "          measure == 'average_clustering' or\n",
    "          measure == 'local_efficiency' or\n",
    "          measure == 'global_efficiency' or\n",
    "          measure == 'assortativity' or\n",
    "          measure == 'clustering_coefficient'):\n",
    "        global_ms = [s for s in ms_list]\n",
    "        global_hv = [s for s in hv_list]\n",
    "    else:\n",
    "        if centrality == 'mean':\n",
    "            global_ms = [mean(s) for s in ms_list]\n",
    "            global_hv = [mean(s) for s in hv_list]\n",
    "        elif centrality ==  'median':\n",
    "            global_ms = [median(s) for s in ms_list]\n",
    "            global_hv = [median(s) for s in hv_list]\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported centrality measure: {centrality}\")\n",
    "   \n",
    "    _, p_value_shapiro_ms = stats.shapiro(global_ms)\n",
    "    _, p_value_shapiro_hv = stats.shapiro(global_hv)\n",
    "\n",
    "    if p_value_shapiro_ms > 0.05 and p_value_shapiro_hv > 0.05:\n",
    "        test = 'ttest'\n",
    "        stat, p_value = stats.ttest_ind(global_ms, global_hv)\n",
    "    else:\n",
    "        test = 'mann-whitney'\n",
    "        stat, p_value = stats.mannwhitneyu(global_ms, global_hv)\n",
    "    \n",
    "    if test == 'ttest':\n",
    "        if p_value < 0.001:\n",
    "            print(f\"t-statistic: {stat}, p < 0.001\")\n",
    "        else:\n",
    "            print(f\"t-statistic: {stat}, p = {p_value:.3f}\")\n",
    "\n",
    "    elif test == 'mann-whitney':\n",
    "        if p_value < 0.001:\n",
    "            print(f\"mann-whitney-statistic: {stat}, p < 0.001\")\n",
    "        else:\n",
    "            print(f\"mann-whitney-statistic: {stat}, p = {p_value:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94c84387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return global graph measures:\n",
    "\n",
    "def return_global(data, measure='degree', weight='weight', centrality='mean', network='global', \n",
    "               layer='single'):\n",
    "    data_list = calculate_graph_measures(data, measure=measure, weight=weight, layer=layer)\n",
    "    \n",
    "    if measure == 'degree' or network != 'global':\n",
    "        if centrality == 'mean':\n",
    "            global_list = [np.mean(list(s.values())) for s in data_list]\n",
    "        elif centrality ==  'median':\n",
    "            global_list = [np.median(list(s.values())) for s in data_list]\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported centrality measure: {centrality}\")\n",
    "    elif (measure == 'node_degree' or\n",
    "          measure == 'average_clustering' or\n",
    "          measure == 'local_efficiency' or\n",
    "          measure == 'global_efficiency' or\n",
    "          measure == 'assortativity'or\n",
    "          measure == 'clustering_coefficient'):\n",
    "        global_list = [s for s in data_list]\n",
    "    else:\n",
    "        if centrality == 'mean':\n",
    "            global_list = [mean(s) for s in data_list]\n",
    "        elif centrality ==  'median':\n",
    "            global_list = [median(s) for s in data_list]\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported centrality measure: {centrality}\")\n",
    "            \n",
    "    return global_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fb00156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independence test for nodal measures:\n",
    "\n",
    "def stats_nodal_test(ms=ms_st, hv=hv_st, measure='degree', weight='weight', verbose=True, network='nodal', \n",
    "                     layer='single', sn=False):\n",
    "    ms_list = calculate_graph_measures(ms, measure=measure, weight=weight, network=network)\n",
    "    hv_list = calculate_graph_measures(hv, measure=measure, weight=weight, network=network)\n",
    "            \n",
    "    nodes_ms = [[d[key] for d in ms_list] for key in ms_list[0]]\n",
    "    nodes_hv = [[d[key] for d in hv_list] for key in hv_list[0]]\n",
    "    \n",
    "    \n",
    "    significant_nodes = []\n",
    "    significant_nodes_measures_ms = []\n",
    "    significant_nodes_measures_hv = []\n",
    "    \n",
    "    for i in range(len(nodes_ms)):\n",
    "        _, p_value_shapiro_ms = stats.shapiro(nodes_ms)\n",
    "        _, p_value_shapiro_hv = stats.shapiro(nodes_hv)\n",
    "        \n",
    "        if p_value_shapiro_ms > 0.05 and p_value_shapiro_hv > 0.05:\n",
    "            test = 'ttest'\n",
    "        else:\n",
    "            test = 'mann-whitney'\n",
    "        \n",
    "        if test == 'ttest':\n",
    "            stat, p_value = stats.ttest_ind(nodes_ms[i], nodes_hv[i])\n",
    "        elif test == 'mann-whitney':\n",
    "            stat, p_value = stats.mannwhitneyu(nodes_ms[i], nodes_hv[i])\n",
    "        \n",
    "        if verbose:\n",
    "            if p_value < 0.001:\n",
    "                print(f\"statistic: {stat}, p < 0.001\")\n",
    "                print(\"  Significant\")\n",
    "            elif p_value < 0.05:\n",
    "                print(f\"statistic: {stat}, p = {p_value:.3f}\")\n",
    "                print(\"  Significant\")\n",
    "            else:\n",
    "                print(f\"statistic: {stat}, p = {p_value:.3f}\")\n",
    "                \n",
    "\n",
    "        # Check if the p-value is less than 0.01\n",
    "        if p_value < 0.001:\n",
    "            significant_nodes.append(i+1)\n",
    "            significant_nodes_measures_ms.append(nodes_ms[i])\n",
    "            significant_nodes_measures_hv.append(nodes_hv[i])\n",
    "            \n",
    "    print(f\"Amount of significant nodes: {len(significant_nodes)}/76\")\n",
    "    print(f\"List of significant nodes: {significant_nodes}\")\n",
    "    print(f\"Test used: {test}\")\n",
    "    \n",
    "    significant_nodes_measures_ms = np.array(significant_nodes_measures_ms)\n",
    "    significant_nodes_measures_hv = np.array(significant_nodes_measures_hv)\n",
    "    \n",
    "    summary_nodes = \"{}/76\".format(len(significant_nodes))\n",
    "    \n",
    "    if sn:\n",
    "        return significant_nodes_measures_ms, significant_nodes_measures_hv, significant_nodes\n",
    "    else:\n",
    "        return significant_nodes_measures_ms, significant_nodes_measures_hv, summary_nodes\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a84613a",
   "metadata": {},
   "source": [
    "<a id='a4'></a>\n",
    "<h1>Graph measures</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f90696",
   "metadata": {},
   "source": [
    "Now we use the functions to calculate independence between groups using graph measures. Each measure affords a different kind of calculation, some are only global, some only nodal, some both. For nodal tests, we print out a list of the nodes where we find a significant difference between groups. For each section, we first check for differences between patients and controls, and under the subsection \"Phenotype\" we look for differences between rrms patients and ppms/spms patints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838670cc",
   "metadata": {},
   "source": [
    "<a id='a4.1'></a>\n",
    "<h2>Strength</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45074193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical test for difference between global strengths (structural):\n",
      "mann-whitney-statistic: 393.0, p < 0.001\n"
     ]
    }
   ],
   "source": [
    "print(\"Statistical test for difference between global strengths (structural):\")\n",
    "stats_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6024d75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical test for difference between global strengths (functional):\n",
      "mann-whitney-statistic: 1573.0, p = 0.192\n"
     ]
    }
   ],
   "source": [
    "print(\"Statistical test for difference between global strengths (functional):\")\n",
    "stats_test(ms=ms_func, hv=hv_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4a38da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical test for difference between global strengths (combined):\n",
      "mann-whitney-statistic: 884.0, p = 0.022\n"
     ]
    }
   ],
   "source": [
    "print(\"Statistical test for difference between global strengths (combined):\")\n",
    "stats_test(ms=ms_combined, hv=hv_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2696c719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical test for nodal strength differences (structural):\n",
      "Amount of significant nodes: 54/76\n",
      "List of significant nodes: [2, 3, 4, 5, 6, 8, 9, 10, 11, 13, 14, 15, 17, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 32, 33, 36, 38, 39, 40, 43, 44, 45, 47, 48, 51, 53, 54, 55, 56, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74]\n",
      "Test used: mann-whitney\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vant/anaconda3/envs/svm/lib/python3.11/site-packages/scipy/stats/_morestats.py:1882: UserWarning: p-value may not be accurate for N > 5000.\n",
      "  warnings.warn(\"p-value may not be accurate for N > 5000.\")\n"
     ]
    }
   ],
   "source": [
    "print(\"Statistical test for nodal strength differences (structural):\")\n",
    "significant_nodes_ms_strength, significant_nodes_hv_strength, nodal_strength_st = stats_nodal_test(ms_st, hv_st, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be5dc251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'54/76'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodal_strength_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c677d919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical test for nodal strength differences (functional):\n",
      "Amount of significant nodes: 0/76\n",
      "List of significant nodes: []\n",
      "Test used: mann-whitney\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=float64), array([], dtype=float64), '0/76')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Statistical test for nodal strength differences (functional):\")\n",
    "stats_nodal_test(ms=ms_func, hv=hv_func, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97ff020a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of significant nodes: 5/76\n",
      "List of significant nodes: [43, 45, 56, 59, 64]\n",
      "Test used: mann-whitney\n"
     ]
    }
   ],
   "source": [
    "significant_nodes_ms_strength_combined, significant_nodes_hv_strength_combined, nodal_strength_comb = stats_nodal_test(ms=ms_combined, hv=hv_combined, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b609e6",
   "metadata": {},
   "source": [
    "<h3>Phenotypes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66032ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical test for difference between global strengths of phenotypes(structural):\n",
      "mann-whitney-statistic: 1573.0, p = 0.284\n"
     ]
    }
   ],
   "source": [
    "print(\"Statistical test for difference between global strengths of phenotypes(structural):\")\n",
    "stats_test(ms=ms_rr, hv=ms_psp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f2e68a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical test for difference between global strengths of phenotypes(functional):\n",
      "mann-whitney-statistic: 1358.0, p = 0.929\n"
     ]
    }
   ],
   "source": [
    "print(\"Statistical test for difference between global strengths of phenotypes(functional):\")\n",
    "stats_test(ms=ms_rr_func, hv=ms_psp_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed2ca5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical test for nodal strength differences of phenotypes(structural):\n",
      "Amount of significant nodes: 0/76\n",
      "List of significant nodes: []\n",
      "Test used: mann-whitney\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=float64), array([], dtype=float64), '0/76')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Statistical test for nodal strength differences of phenotypes(structural):\")\n",
    "stats_nodal_test(ms=ms_rr, hv=ms_psp, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4e34a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical test for nodal strength differences of phenotypes(functional):\n",
      "Amount of significant nodes: 1/76\n",
      "List of significant nodes: [42]\n",
      "Test used: mann-whitney\n"
     ]
    }
   ],
   "source": [
    "print(\"Statistical test for nodal strength differences of phenotypes(functional):\")\n",
    "significant_strength_rr, significant_strength_psp, nodes_strength_phe = stats_nodal_test(ms=ms_rr_func, hv=ms_psp_func, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42eedeae",
   "metadata": {},
   "source": [
    "<a id='a4.2'></a>\n",
    "<h2>Node Degree</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45963c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Node Degrees for Each MS Graph:\n",
      "[3266, 3488, 3412, 3450, 3460, 3474, 3396, 3440, 3446, 3478, 3486, 3478, 3594, 3434, 3472, 3396, 3594, 3482, 3438, 3450, 2922, 3392, 3410, 3486, 3506, 3490, 3452, 3390, 3356, 3460, 3482, 3478, 3478, 3468, 3524, 3412, 3512, 3466, 3482, 3390, 3394, 3386, 3400, 3462, 3468, 3454, 3594, 3468, 3430, 3500, 3466, 3402, 3442, 2756, 3380, 3480, 3348, 3222, 3494, 3596, 3210, 3332, 3430, 3376, 3470, 3594, 3444, 3480, 3594, 3182, 3396, 3452, 3594, 3466, 3430, 3594, 3488, 3594, 3594, 3442, 3458, 3504, 3404, 3372, 3202, 3248, 2870, 3060, 3164, 3240, 3254, 3012, 3272, 3158, 3274, 3196, 3222, 2860, 3178, 3050, 2462, 3268, 2920, 3296, 3160, 3054, 3228, 2448, 3346, 3050, 3420, 3328, 3186, 3082, 3146, 2998, 3260, 3120, 3000, 3342, 3262, 3158, 3294, 3242, 3250, 3176, 3056, 3110, 3390, 3194, 3382, 3036, 3254, 2552, 3326, 2994, 3170, 3330, 3268, 3306, 3184, 3158, 3008, 2870, 3066, 3066, 2878]\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Node Degrees for Each MS Graph:\")\n",
    "print(calculate_graph_measures(ms_st, measure='node_degree'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5d47f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Node Degrees for Each HV Graph:\n",
      "[3538, 3414, 3532, 3480, 3512, 3524, 3472, 3540, 3506, 3546, 3214, 3104, 3328, 3222, 3392, 3358, 3154, 3322]\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Node Degrees for Each HV Graph:\")\n",
    "print(calculate_graph_measures(hv_st, measure='node_degree'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8592d9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global node degree test (structural):\n",
      "mann-whitney-statistic: 960.0, p = 0.058\n"
     ]
    }
   ],
   "source": [
    "print(\"Global node degree test (structural):\")\n",
    "stats_test(measure='node_degree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cca3337b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global node degree test (functional):\n",
      "t-statistic: 2.9538359157980647, p = 0.004\n"
     ]
    }
   ],
   "source": [
    "print(\"Global node degree test (functional):\")\n",
    "stats_test(ms=ms_func, hv=hv_func, measure='node_degree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b1974ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global node degree test (combined):\n",
      "mann-whitney-statistic: 1295.5, p = 0.888\n"
     ]
    }
   ],
   "source": [
    "print(\"Global node degree test (combined):\")\n",
    "stats_test(ms=ms_combined, hv=hv_combined, measure='node_degree')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0f0bbb",
   "metadata": {},
   "source": [
    "<h3>Phenotypes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fdd647e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global node degree test for phenotypes (structural):\n",
      "mann-whitney-statistic: 1619.0, p = 0.186\n"
     ]
    }
   ],
   "source": [
    "print(\"Global node degree test for phenotypes (structural):\")\n",
    "stats_test(ms=ms_rr, hv=ms_psp, measure='node_degree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "efe6d8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global node degree test for phenotypes (functional):\n",
      "t-statistic: 0.6178329223909763, p = 0.538\n"
     ]
    }
   ],
   "source": [
    "print(\"Global node degree test for phenotypes (functional):\")\n",
    "stats_test(ms=ms_rr_func, hv=ms_psp_func, measure='node_degree')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc17370f",
   "metadata": {},
   "source": [
    "<a id='a4.3'></a>\n",
    "<h2>Degree Centrality</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f34ec41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global degree centrality test (structural):\n",
      "mann-whitney-statistic: 960.0, p = 0.058\n"
     ]
    }
   ],
   "source": [
    "print(\"Global degree centrality test (structural):\")\n",
    "stats_test(measure='degree_centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8d95b561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global degree centrality test (functional):\n",
      "t-statistic: 2.9538359157980656, p = 0.004\n"
     ]
    }
   ],
   "source": [
    "print(\"Global degree centrality test (functional):\")\n",
    "stats_test(ms=ms_func, hv=hv_func, measure='degree_centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d4caf36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global degree centrality test (combined):\n",
      "mann-whitney-statistic: 1297.0, p = 0.894\n"
     ]
    }
   ],
   "source": [
    "print(\"Global degree centrality test (combined):\")\n",
    "stats_test(ms=ms_combined, hv=hv_combined, measure='degree_centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d71f6871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical test for nodal degree centrality (structural):\n",
      "Amount of significant nodes: 3/76\n",
      "List of significant nodes: [36, 40, 43]\n",
      "Test used: mann-whitney\n"
     ]
    }
   ],
   "source": [
    "print(\"Statistical test for nodal degree centrality (structural):\")\n",
    "significant_nodes_ms_dc, significant_nodes_hv_dc, nodal_dc_st = stats_nodal_test(ms_st, hv_st, measure='degree_centrality', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d76be040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical test for nodal degree centrality (functional):\n",
      "Amount of significant nodes: 1/76\n",
      "List of significant nodes: [53]\n",
      "Test used: mann-whitney\n"
     ]
    }
   ],
   "source": [
    "print(\"Statistical test for nodal degree centrality (functional):\")\n",
    "significant_nodes_ms_dc_func, significant_nodes_hv_dc_func, nodal_dc_func = stats_nodal_test(ms=ms_func, hv=hv_func, measure='degree_centrality', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a906fd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical test for nodal degree centrality (combined):\n",
      "Amount of significant nodes: 0/76\n",
      "List of significant nodes: []\n",
      "Test used: mann-whitney\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=float64), array([], dtype=float64), '0/76')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Statistical test for nodal degree centrality (combined):\")\n",
    "stats_nodal_test(ms=ms_combined, hv=hv_combined, measure='degree_centrality', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1014aaa5",
   "metadata": {},
   "source": [
    "<h3>Phenotypes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6d6a333a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global degree centrality test for phenotypes(structural):\n",
      "mann-whitney-statistic: 1619.0, p = 0.186\n"
     ]
    }
   ],
   "source": [
    "print(\"Global degree centrality test for phenotypes(structural):\")\n",
    "stats_test(ms=ms_rr, hv=ms_psp, measure='degree_centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "196d66f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global degree centrality test for phenotypes(functional):\n",
      "t-statistic: 0.6178329223909796, p = 0.538\n"
     ]
    }
   ],
   "source": [
    "print(\"Global degree centrality test for phenotypes(functional):\")\n",
    "stats_test(ms=ms_rr_func, hv=ms_psp_func, measure='degree_centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6231f149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical test for nodal degree centrality phenotypes (structural):\n",
      "Amount of significant nodes: 0/76\n",
      "List of significant nodes: []\n",
      "Test used: mann-whitney\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=float64), array([], dtype=float64), '0/76')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Statistical test for nodal degree centrality phenotypes (structural):\")\n",
    "stats_nodal_test(ms_rr, ms_psp, measure='degree_centrality', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69552772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical test for nodal degree centrality phenotypes (functional):\n",
      "Amount of significant nodes: 0/76\n",
      "List of significant nodes: []\n",
      "Test used: mann-whitney\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=float64), array([], dtype=float64), '0/76')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Statistical test for nodal degree centrality phenotypes (functional):\")\n",
    "stats_nodal_test(ms_rr_func, ms_psp_func, measure='degree_centrality', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b6b2ae",
   "metadata": {},
   "source": [
    "<a id='a4.4'></a>\n",
    "<h2>Closeness centrality</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6abeb031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global closeness centrality test (structural):\n",
      "mann-whitney-statistic: 975.0, p = 0.069\n"
     ]
    }
   ],
   "source": [
    "print(\"Global closeness centrality test (structural):\")\n",
    "stats_test(measure='closeness_centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3b7f744d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global closeness centrality test (functional):\n",
      "t-statistic: 3.0222420670603247, p = 0.003\n"
     ]
    }
   ],
   "source": [
    "print(\"Global closeness centrality test (functional):\")\n",
    "stats_test(ms=ms_func, hv=hv_func, measure='closeness_centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "14cfae20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mann-whitney-statistic: 1289.0, p = 0.861\n"
     ]
    }
   ],
   "source": [
    "stats_test(ms=ms_combined, hv=hv_combined, measure='closeness_centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "12795864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical test for nodal closeness centrality (structural):\n",
      "Amount of significant nodes: 3/76\n",
      "List of significant nodes: [36, 40, 43]\n",
      "Test used: mann-whitney\n"
     ]
    }
   ],
   "source": [
    "print(\"Statistical test for nodal closeness centrality (structural):\")\n",
    "significant_nodes_ms_cc, significant_nodes_hv_cc, nodal_cc_st = stats_nodal_test(measure='closeness_centrality', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5c8afdaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical test for nodal closeness centrality (functional):\n",
      "Amount of significant nodes: 1/76\n",
      "List of significant nodes: [53]\n",
      "Test used: mann-whitney\n"
     ]
    }
   ],
   "source": [
    "print(\"Statistical test for nodal closeness centrality (functional):\")\n",
    "significant_nodes_ms_cc_func, significant_nodes_hv_cc_func, nodal_cc_func = stats_nodal_test(ms=ms_func, hv=hv_func, measure='closeness_centrality', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c33880f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical test for nodal closeness centrality (combined):\n",
      "Amount of significant nodes: 0/76\n",
      "List of significant nodes: []\n",
      "Test used: mann-whitney\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=float64), array([], dtype=float64), '0/76')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Statistical test for nodal closeness centrality (combined):\")\n",
    "stats_nodal_test(ms=ms_combined, hv=hv_combined, measure='closeness_centrality', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdd324c",
   "metadata": {},
   "source": [
    "<h3>Phenotypes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4d096d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global closeness centrality test (structural):\n",
      "mann-whitney-statistic: 1621.0, p = 0.183\n"
     ]
    }
   ],
   "source": [
    "print(\"Global closeness centrality test (structural):\")\n",
    "stats_test(ms=ms_rr, hv=ms_psp, measure='closeness_centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4c3e699a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global closeness centrality test (functional):\n",
      "t-statistic: 0.5602840974310408, p = 0.576\n"
     ]
    }
   ],
   "source": [
    "print(\"Global closeness centrality test (functional):\")\n",
    "stats_test(ms=ms_rr_func, hv=ms_psp_func, measure='closeness_centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fb404e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical test for nodal closeness centrality (structural):\n",
      "Amount of significant nodes: 0/76\n",
      "List of significant nodes: []\n",
      "Test used: mann-whitney\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=float64), array([], dtype=float64), '0/76')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Statistical test for nodal closeness centrality (structural):\")\n",
    "stats_nodal_test(ms=ms_rr, hv=ms_psp, measure='closeness_centrality', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d086ddfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical test for nodal closeness centrality (functional):\n",
      "Amount of significant nodes: 0/76\n",
      "List of significant nodes: []\n",
      "Test used: mann-whitney\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=float64), array([], dtype=float64), '0/76')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Statistical test for nodal closeness centrality (functional):\")\n",
    "stats_nodal_test(ms=ms_rr_func, hv=ms_psp_func, measure='closeness_centrality', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bfa7a5",
   "metadata": {},
   "source": [
    "<a id='a4.5'></a>\n",
    "<h2>Clustering coefficient</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f05c012d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global clustering coefficient test (structural):\n",
      "mann-whitney-statistic: 1127.0, p = 0.307\n"
     ]
    }
   ],
   "source": [
    "print(\"Global clustering coefficient test (structural):\")\n",
    "stats_test(measure='average_clustering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ae91d8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global clustering coefficient test (functional):\n",
      "t-statistic: 2.811489986718919, p = 0.006\n"
     ]
    }
   ],
   "source": [
    "print(\"Global clustering coefficient test (functional):\")\n",
    "stats_test(ms=ms_func, hv=hv_func, measure='average_clustering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "79d90e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mann-whitney-statistic: 1310.0, p = 0.948\n"
     ]
    }
   ],
   "source": [
    "stats_test(ms=ms_combined, hv=hv_combined, measure='average_clustering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7e5708c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical test for nodal clustering coefficient (structural):\n",
      "Amount of significant nodes: 0/76\n",
      "List of significant nodes: []\n",
      "Test used: mann-whitney\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=float64), array([], dtype=float64), '0/76')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Statistical test for nodal clustering coefficient (structural):\")\n",
    "stats_nodal_test(measure='clustering', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1fd7f1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical test for nodal clustering coefficient (functional):\n",
      "Amount of significant nodes: 1/76\n",
      "List of significant nodes: [30]\n",
      "Test used: mann-whitney\n"
     ]
    }
   ],
   "source": [
    "print(\"Statistical test for nodal clustering coefficient (functional):\")\n",
    "significant_nodes_ms_cluster_func, significant_nodes_hv_cluster_func, nodal_clustering_func = stats_nodal_test(ms=ms_func, hv=hv_func, measure='clustering', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e40e81f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical test for nodal clustering coefficient (combined):\n",
      "Amount of significant nodes: 0/76\n",
      "List of significant nodes: []\n",
      "Test used: mann-whitney\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=float64), array([], dtype=float64), '0/76')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Statistical test for nodal clustering coefficient (combined):\")\n",
    "stats_nodal_test(ms=ms_combined, hv=hv_combined, measure='clustering', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbbe188",
   "metadata": {},
   "source": [
    "<h3>Phenotypes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "78225d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global clustering coefficient test (structural):\n",
      "mann-whitney-statistic: 1596.0, p = 0.231\n"
     ]
    }
   ],
   "source": [
    "print(\"Global clustering coefficient test (structural):\")\n",
    "stats_test(ms=ms_rr, hv=ms_psp, measure='average_clustering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "09b0d376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global clustering coefficient test (functional):\n",
      "t-statistic: 0.4862288390254382, p = 0.628\n"
     ]
    }
   ],
   "source": [
    "print(\"Global clustering coefficient test (functional):\")\n",
    "stats_test(ms=ms_rr_func, hv=ms_psp_func, measure='average_clustering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "128ad91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical test for nodal clustering coefficient (structural):\n",
      "Amount of significant nodes: 0/76\n",
      "List of significant nodes: []\n",
      "Test used: mann-whitney\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=float64), array([], dtype=float64), '0/76')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Statistical test for nodal clustering coefficient (structural):\")\n",
    "stats_nodal_test(ms=ms_rr, hv=ms_psp, measure='clustering', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c4ded3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical test for nodal clustering coefficient (functional):\n",
      "Amount of significant nodes: 0/76\n",
      "List of significant nodes: []\n",
      "Test used: mann-whitney\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=float64), array([], dtype=float64), '0/76')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Statistical test for nodal clustering coefficient (functional):\")\n",
    "stats_nodal_test(ms=ms_rr_func, hv=ms_psp_func, measure='clustering', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130e57d2",
   "metadata": {},
   "source": [
    "<a id='a4.6'></a>\n",
    "<h2>Local Efficiency</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "53ebec41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local efficiency test (structural):\n",
      "mann-whitney-statistic: 1127.0, p = 0.307\n"
     ]
    }
   ],
   "source": [
    "print(\"Local efficiency test (structural):\")\n",
    "stats_test(measure='local_efficiency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c5d03739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local efficiency test (functional):\n",
      "t-statistic: 2.7751763076004203, p = 0.006\n"
     ]
    }
   ],
   "source": [
    "print(\"Local efficiency test (functional):\")\n",
    "stats_test(ms=ms_func, hv=hv_func, measure='local_efficiency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bca27be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local efficiency test (combined):\n",
      "mann-whitney-statistic: 1310.0, p = 0.948\n"
     ]
    }
   ],
   "source": [
    "print(\"Local efficiency test (combined):\")\n",
    "stats_test(ms=ms_combined, hv=hv_combined, measure='local_efficiency')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d65d5a",
   "metadata": {},
   "source": [
    "<h3>Phenotypes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dd383c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local efficiency test (structural):\n",
      "mann-whitney-statistic: 1595.0, p = 0.233\n"
     ]
    }
   ],
   "source": [
    "print(\"Local efficiency test (structural):\")\n",
    "stats_test(ms=ms_rr, hv=ms_psp, measure='local_efficiency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f3d2ebed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local efficiency test (functional):\n",
      "t-statistic: 0.5739715300555817, p = 0.567\n"
     ]
    }
   ],
   "source": [
    "print(\"Local efficiency test (functional):\")\n",
    "stats_test(ms=ms_rr_func, hv=ms_psp_func, measure='local_efficiency')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a7164b",
   "metadata": {},
   "source": [
    "<a id='a4.7'></a>\n",
    "<h2>Global efficiency</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "67adaf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global efficiency test (structural):\n",
      "mann-whitney-statistic: 960.5, p = 0.058\n"
     ]
    }
   ],
   "source": [
    "print(\"Global efficiency test (structural):\")\n",
    "stats_test(measure='global_efficiency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4659c1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global efficiency test (functional):\n",
      "t-statistic: 3.0434820887042195, p = 0.003\n"
     ]
    }
   ],
   "source": [
    "print(\"Global efficiency test (functional):\")\n",
    "stats_test(ms=ms_func, hv=hv_func, measure='global_efficiency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bc41c133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global efficiency test (combined):\n",
      "mann-whitney-statistic: 1295.5, p = 0.888\n"
     ]
    }
   ],
   "source": [
    "print(\"Global efficiency test (combined):\")\n",
    "stats_test(ms=ms_combined, hv=hv_combined, measure='global_efficiency')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1476c1bb",
   "metadata": {},
   "source": [
    "<h3>Phenotypes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f2718232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global efficiency test (structural):\n",
      "mann-whitney-statistic: 1620.0, p = 0.184\n"
     ]
    }
   ],
   "source": [
    "print(\"Global efficiency test (structural):\")\n",
    "stats_test(ms=ms_rr, hv=ms_psp, measure='global_efficiency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "990cfac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global efficiency test (functional):\n",
      "t-statistic: 0.5972349699312437, p = 0.551\n"
     ]
    }
   ],
   "source": [
    "print(\"Global efficiency test (functional):\")\n",
    "stats_test(ms=ms_rr_func, hv=ms_psp_func, measure='global_efficiency')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178d0b6f",
   "metadata": {},
   "source": [
    "<a id='a4.8'></a>\n",
    "<h2>Betweenness Centrality</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e5461a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global betweenness centrality test (structural):\n",
      "mann-whitney-statistic: 1686.5, p = 0.058\n"
     ]
    }
   ],
   "source": [
    "print(\"Global betweenness centrality test (structural):\")\n",
    "stats_test(measure='betweenness_centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "abfdf438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global betweenness centrality test (functional):\n",
      "t-statistic: -3.2044492356268512, p = 0.002\n"
     ]
    }
   ],
   "source": [
    "print(\"Global betweenness centrality test (functional):\")\n",
    "stats_test(ms=ms_func, hv=hv_func, measure='betweenness_centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "462c78be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global betweenness centrality test (combined):\n",
      "mann-whitney-statistic: 1349.0, p = 0.894\n"
     ]
    }
   ],
   "source": [
    "print(\"Global betweenness centrality test (combined):\")\n",
    "stats_test(ms=ms_combined, hv=hv_combined, measure='betweenness_centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d8ab6594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical nodal test for betweenness centrality (structural):\n",
      "Amount of significant nodes: 1/76\n",
      "List of significant nodes: [45]\n",
      "Test used: mann-whitney\n"
     ]
    }
   ],
   "source": [
    "print(\"Statistical nodal test for betweenness centrality (structural):\")\n",
    "significant_nodes_ms_bc, significant_nodes_hv_bc, nodal_bc_st = stats_nodal_test(measure='betweenness_centrality', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ec689a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical nodal test for betweenness centrality (functional):\n",
      "Amount of significant nodes: 2/76\n",
      "List of significant nodes: [59, 71]\n",
      "Test used: mann-whitney\n"
     ]
    }
   ],
   "source": [
    "print(\"Statistical nodal test for betweenness centrality (functional):\")\n",
    "significant_nodes_ms_bc_func, significant_nodes_hv_bc_func, nodal_bc_func = stats_nodal_test(ms=ms_func, hv=hv_func, measure='betweenness_centrality', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "96440b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical nodal test for betweenness centrality (combined):\n",
      "Amount of significant nodes: 1/76\n",
      "List of significant nodes: [6]\n",
      "Test used: mann-whitney\n"
     ]
    }
   ],
   "source": [
    "print(\"Statistical nodal test for betweenness centrality (combined):\")\n",
    "significant_nodes_ms_bc_combined, significant_nodes_hv_bc_combined, nodal_bc_comb = stats_nodal_test(ms=ms_combined, hv=hv_combined, measure='betweenness_centrality', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2a1202",
   "metadata": {},
   "source": [
    "<h3>Phenotypes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e21f7bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global betweenness centrality test (structural):\n",
      "mann-whitney-statistic: 1127.5, p = 0.180\n"
     ]
    }
   ],
   "source": [
    "print(\"Global betweenness centrality test (structural):\")\n",
    "stats_test(ms=ms_rr, hv=ms_psp, measure='betweenness_centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "905c5245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global betweenness centrality test (functional):\n",
      "t-statistic: -0.5563181214287746, p = 0.579\n"
     ]
    }
   ],
   "source": [
    "print(\"Global betweenness centrality test (functional):\")\n",
    "stats_test(ms=ms_rr_func, hv=ms_psp_func, measure='betweenness_centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1d659386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodal test for betweenness centrality (structural):\n",
      "Amount of significant nodes: 0/76\n",
      "List of significant nodes: []\n",
      "Test used: mann-whitney\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=float64), array([], dtype=float64), '0/76')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Nodal test for betweenness centrality (structural):\")\n",
    "stats_nodal_test(ms=ms_rr, hv=ms_psp, measure='betweenness_centrality', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "70fb965e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodal test for betweenness centrality (functional):\n",
      "Amount of significant nodes: 0/76\n",
      "List of significant nodes: []\n",
      "Test used: mann-whitney\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=float64), array([], dtype=float64), '0/76')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Nodal test for betweenness centrality (functional):\")\n",
    "stats_nodal_test(ms=ms_rr_func, hv=ms_psp_func, measure='betweenness_centrality', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dd4f2c",
   "metadata": {},
   "source": [
    "<a id='a4.9'></a>\n",
    "<h2>Eigenvector Centrality</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e1bb3264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global eigenvector centrality test (structural):\n",
      "mann-whitney-statistic: 807.0, p = 0.007\n"
     ]
    }
   ],
   "source": [
    "print(\"Global eigenvector centrality test (structural):\")\n",
    "stats_test(measure='eigenvector_centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "42420f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global eigenvector centrality test (functional):\n",
      "mann-whitney-statistic: 1615.0, p = 0.128\n"
     ]
    }
   ],
   "source": [
    "print(\"Global eigenvector centrality test (functional):\")\n",
    "stats_test(ms=ms_func, hv=hv_func, measure='eigenvector_centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b2f76f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global eigenvector centrality test (combined):\n",
      "mann-whitney-statistic: 1039.0, p = 0.138\n"
     ]
    }
   ],
   "source": [
    "print(\"Global eigenvector centrality test (combined):\")\n",
    "stats_test(ms=ms_combined, hv=hv_combined, measure='eigenvector_centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f0eb83d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical nodal test for eigenvector centrality (structural):\n",
      "Amount of significant nodes: 5/76\n",
      "List of significant nodes: [36, 43, 46, 61, 64]\n",
      "Test used: mann-whitney\n"
     ]
    }
   ],
   "source": [
    "print(\"Statistical nodal test for eigenvector centrality (structural):\")\n",
    "significant_nodes_ms_ec, significant_nodes_hv_ec, nodal_ec_st = stats_nodal_test(measure='eigenvector_centrality', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "119b8cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical nodal test for eigenvector centrality (functional):\n",
      "Amount of significant nodes: 0/76\n",
      "List of significant nodes: []\n",
      "Test used: mann-whitney\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=float64), array([], dtype=float64), '0/76')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Statistical nodal test for eigenvector centrality (functional):\")\n",
    "stats_nodal_test(ms=ms_func, hv=hv_func, measure='eigenvector_centrality', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "849971a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical nodal test for eigenvector centrality (combined):\n",
      "Amount of significant nodes: 0/76\n",
      "List of significant nodes: []\n",
      "Test used: mann-whitney\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=float64), array([], dtype=float64), '0/76')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Statistical nodal test for eigenvector centrality (combined):\")\n",
    "stats_nodal_test(ms=ms_combined, hv=hv_combined, measure='eigenvector_centrality', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c070bb",
   "metadata": {},
   "source": [
    "<h3>Phenotypes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "23fedc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global eigenvector centrality test (structural):\n",
      "mann-whitney-statistic: 1642.0, p = 0.148\n"
     ]
    }
   ],
   "source": [
    "print(\"Global eigenvector centrality test (structural):\")\n",
    "stats_test(ms=ms_rr, hv=ms_psp, measure='eigenvector_centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "98e98da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global eigenvector centrality test (functional):\n",
      "mann-whitney-statistic: 1026.0, p = 0.058\n"
     ]
    }
   ],
   "source": [
    "print(\"Global eigenvector centrality test (functional):\")\n",
    "stats_test(ms=ms_rr_func, hv=ms_psp_func, measure='eigenvector_centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2f4596f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical test for eigenvector centrality (structural):\n",
      "Amount of significant nodes: 0/76\n",
      "List of significant nodes: []\n",
      "Test used: mann-whitney\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=float64), array([], dtype=float64), '0/76')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Statistical test for eigenvector centrality (structural):\")\n",
    "stats_nodal_test(ms=ms_rr, hv=ms_psp, measure='eigenvector_centrality', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1a06b570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical test for eigenvector centrality (functional):\n",
      "Amount of significant nodes: 0/76\n",
      "List of significant nodes: []\n",
      "Test used: mann-whitney\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=float64), array([], dtype=float64), '0/76')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Statistical test for eigenvector centrality (functional):\")\n",
    "stats_nodal_test(ms=ms_rr_func, hv=ms_psp_func, measure='eigenvector_centrality', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b35605",
   "metadata": {},
   "source": [
    "<a id='a4.10'></a>\n",
    "<h2>Assortativity</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "50c33ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global assortativity test (structural):\n",
      "mann-whitney-statistic: 1628.0, p = 0.111\n"
     ]
    }
   ],
   "source": [
    "print(\"Global assortativity test (structural):\")\n",
    "stats_test(measure='assortativity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cdae0999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global assortativity test (functional):\n",
      "mann-whitney-statistic: 896.0, p = 0.026\n"
     ]
    }
   ],
   "source": [
    "print(\"Global assortativity test (functional):\")\n",
    "stats_test(ms=ms_func, hv=hv_func, measure='assortativity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7fa41382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mann-whitney-statistic: 1576.0, p = 0.187\n"
     ]
    }
   ],
   "source": [
    "stats_test(ms=ms_combined, hv=hv_combined, measure='assortativity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac52adb1",
   "metadata": {},
   "source": [
    "<h3>Phenotypes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "31d27e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global assortativity test (structural):\n",
      "mann-whitney-statistic: 1225.0, p = 0.417\n"
     ]
    }
   ],
   "source": [
    "print(\"Global assortativity test (structural):\")\n",
    "stats_test(ms=ms_rr, hv=ms_psp, measure='assortativity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1e23eeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global assortativity test (functional):\n",
      "mann-whitney-statistic: 1559.0, p = 0.319\n"
     ]
    }
   ],
   "source": [
    "print(\"Global assortativity test (functional):\")\n",
    "stats_test(ms=ms_rr_func, hv=ms_psp_func, measure='assortativity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cb398f",
   "metadata": {},
   "source": [
    "<a id='a4.11'></a>\n",
    "<h2>Rich Club</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "673d37aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global rich club test (structural):\n",
      "mann-whitney-statistic: 870.5, p = 0.017\n"
     ]
    }
   ],
   "source": [
    "print(\"Global rich club test (structural):\")\n",
    "stats_test(measure='rich_club')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9bf3d666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global rich club test (functional):\n",
      "t-statistic: 3.444584978966663, p < 0.001\n"
     ]
    }
   ],
   "source": [
    "print(\"Global rich club test (functional):\")\n",
    "stats_test(ms=ms_func, hv=hv_func, measure='rich_club')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3a0b0b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global rich club test (combined):\n",
      "mann-whitney-statistic: 1205.5, p = 0.527\n"
     ]
    }
   ],
   "source": [
    "print(\"Global rich club test (combined):\")\n",
    "stats_test(ms=ms_combined, hv=hv_combined, measure='rich_club')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df02d4fe",
   "metadata": {},
   "source": [
    "<h3>Phenotypes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9067e82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global rich club test (structural):\n",
      "mann-whitney-statistic: 1651.0, p = 0.132\n"
     ]
    }
   ],
   "source": [
    "print(\"Global rich club test (structural):\")\n",
    "stats_test(ms=ms_rr, hv=ms_psp, measure='rich_club')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "11217202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global rich club test (functional):\n",
      "t-statistic: 1.3337455970759524, p = 0.184\n"
     ]
    }
   ],
   "source": [
    "print(\"Global rich club test (functional):\")\n",
    "stats_test(ms=ms_rr_func, hv=ms_psp_func, measure='rich_club')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f23adb",
   "metadata": {},
   "source": [
    "<a id='a4.11.1'></a>\n",
    "<h3>Results</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4ccae0",
   "metadata": {},
   "source": [
    "From the global graph measures, only strength obtains a significance p<0.001 when comparing the structural networks of patients and controls. Rich Club also is p<0.001, but when using the functional networks. There is no global measure where we obtain a significant difference between phenotype groups.\n",
    "\n",
    "As to the nodal measures, we have been obtaining lists of nodes with significant differences between patients and controls. Here, we summarize the amount of nodes with significant differences for each of the nodal graph measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "97bdabf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_nodes = pd.DataFrame()\n",
    "\n",
    "table_nodes['strength'] = [nodal_strength_st, 'n.a', nodal_strength_comb]\n",
    "table_nodes['degree centrality'] = [nodal_dc_st, nodal_dc_func, 'n.a']\n",
    "table_nodes['closeness  centrality'] = [nodal_cc_st, nodal_cc_func, 'n.a.']\n",
    "table_nodes['clustering coefficient'] = ['n.a.', nodal_clustering_func, 'n.a.']\n",
    "table_nodes['betweenness centrality'] = [nodal_bc_st, nodal_bc_func, nodal_bc_comb]\n",
    "table_nodes['eigenvector centrality'] = [nodal_ec_st, 'n.a.', 'n.a.']\n",
    "\n",
    "table_nodes['type'] = ['structural', 'functional', 'combined']\n",
    "table_nodes = table_nodes.set_index('type')\n",
    "table_nodes.index.name=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "26a047fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of nodes with significant differences between patients and hv controls:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strength</th>\n",
       "      <th>degree centrality</th>\n",
       "      <th>closeness  centrality</th>\n",
       "      <th>clustering coefficient</th>\n",
       "      <th>betweenness centrality</th>\n",
       "      <th>eigenvector centrality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>structural</th>\n",
       "      <td>54/76</td>\n",
       "      <td>3/76</td>\n",
       "      <td>3/76</td>\n",
       "      <td>n.a.</td>\n",
       "      <td>1/76</td>\n",
       "      <td>5/76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>functional</th>\n",
       "      <td>n.a</td>\n",
       "      <td>1/76</td>\n",
       "      <td>1/76</td>\n",
       "      <td>1/76</td>\n",
       "      <td>2/76</td>\n",
       "      <td>n.a.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combined</th>\n",
       "      <td>5/76</td>\n",
       "      <td>n.a</td>\n",
       "      <td>n.a.</td>\n",
       "      <td>n.a.</td>\n",
       "      <td>1/76</td>\n",
       "      <td>n.a.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           strength degree centrality closeness  centrality  \\\n",
       "structural    54/76              3/76                  3/76   \n",
       "functional      n.a              1/76                  1/76   \n",
       "combined       5/76               n.a                  n.a.   \n",
       "\n",
       "           clustering coefficient betweenness centrality  \\\n",
       "structural                   n.a.                   1/76   \n",
       "functional                   1/76                   2/76   \n",
       "combined                     n.a.                   1/76   \n",
       "\n",
       "           eigenvector centrality  \n",
       "structural                   5/76  \n",
       "functional                   n.a.  \n",
       "combined                     n.a.  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Amount of nodes with significant differences between patients and hv controls:\")\n",
    "table_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89fb6e8",
   "metadata": {},
   "source": [
    "<a id='a5'></a>\n",
    "<h1>Classification</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6062b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, precision_score, recall_score, classification_report, f1_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3a6a84",
   "metadata": {},
   "source": [
    "<a id='a5.1'></a>\n",
    "<h2>Functions for FA classification</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "879c8605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for classification, including grid search for best parameters and SMOTE for data augmentation \n",
    "\n",
    "def classify_oversampled(data, connections=False):\n",
    "    \n",
    "    triuim1 = np.triu_indices_from(st_matrices[0], k=1)\n",
    "    X = [np.array(matrix)[triuim1] for matrix in data]\n",
    "\n",
    "    # we convert the list of upper triangles to a 2D array\n",
    "    X = np.array(X)\n",
    "    y = np.array(labels)\n",
    "    \n",
    "    # we use SMOTE for oversampling\n",
    "    smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "    # variables to store the best results\n",
    "    best_accuracy = 0.0\n",
    "    best_precision = 0.0\n",
    "    best_recall = 0.0\n",
    "    best_f1 = 0.0\n",
    "    best_confusion_matrix = None\n",
    "    best_params = None\n",
    "\n",
    "    num_instances = 50\n",
    "\n",
    "    progress_bar = tqdm(total=num_instances, desc=\"Instances\", position=0, leave=True)\n",
    "\n",
    "\n",
    "    for instance in range(num_instances):\n",
    "        \n",
    "        X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "        X_resampled, y_resampled = shuffle(X_resampled, y_resampled, random_state=42)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.25, random_state=24)\n",
    "\n",
    "        clf = SVC()\n",
    "\n",
    "        # Grid search \n",
    "        param_grid = {\"C\": [0.01, 0.1, 1, 10, 100, 200], \"gamma\": [0.001, 0.01, 0.1, 1, 10]}\n",
    "        grid_search = GridSearchCV(clf, param_grid=param_grid, cv=11)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Train \n",
    "        best_clf = SVC(C=grid_search.best_params_['C'], gamma=grid_search.best_params_['gamma'])\n",
    "        best_clf.fit(X_train, y_train)\n",
    "\n",
    "        # Predictions \n",
    "        preds = best_clf.predict(X_test)\n",
    "\n",
    "        # Evaluation\n",
    "        accuracy = accuracy_score(y_test, preds)\n",
    "        precision = precision_score(y_test, preds)\n",
    "        recall = recall_score(y_test, preds)\n",
    "        f1 = f1_score(y_test, preds)\n",
    "        cnf_matrix = confusion_matrix(y_test, preds)\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_precision = precision\n",
    "            best_recall = recall\n",
    "            best_f1 = f1\n",
    "            best_confusion_matrix = cnf_matrix\n",
    "            best_params = grid_search.best_params_\n",
    "\n",
    "            \n",
    "        progress_bar.update(1)\n",
    "\n",
    "    \n",
    "    progress_bar.close()\n",
    "\n",
    "    # Printing the best results\n",
    "    print(\"Best Results:\")\n",
    "    print(\"Best Accuracy: {:.4f}\".format(best_accuracy))\n",
    "    print(\"Best Precision: {:.4f}\".format(best_precision))\n",
    "    print(\"Best Recall: {:.4f}\".format(best_recall))\n",
    "    print(\"Best F1 Score: {:.4f}\".format(best_f1))\n",
    "    print(\"Best Confusion Matrix:\")\n",
    "    print(best_confusion_matrix)\n",
    "    print(\"Best Parameters (C and Gamma):\", best_params)\n",
    "    \n",
    "    if connections: \n",
    "        \n",
    "        X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "        X_resampled, y_resampled = shuffle(X_resampled, y_resampled, random_state=42)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.25, random_state=24)\n",
    "\n",
    "        # Train the final model with the best hyperparameters\n",
    "        final_clf = SVC(C=best_params['C'], gamma=best_params['gamma'], kernel='rbf')\n",
    "        final_clf.fit(X_train, y_train)\n",
    "\n",
    "        # Predictions\n",
    "        preds = final_clf.predict(X_test)\n",
    "\n",
    "        # Evaluation\n",
    "        accuracy = accuracy_score(y_test, preds)\n",
    "        precision = precision_score(y_test, preds)\n",
    "        recall = recall_score(y_test, preds)\n",
    "        cnf_matrix = confusion_matrix(y_test, preds)\n",
    "        \n",
    "        n_sv = final_clf.support_vectors_.shape[0]\n",
    "        feature_importances = np.abs(np.dot(final_clf.dual_coef_, final_clf.support_vectors_)).flatten() / n_sv\n",
    "\n",
    "        top_indices = np.argsort(feature_importances)[-7:][::-1]\n",
    "\n",
    "        # Get the row and column indices for the flattened indices\n",
    "        row_indices, col_indices = np.triu_indices(76, k=1)\n",
    "\n",
    "        # Map the flattened indices to the original matrix indices\n",
    "        top_original_indices = list(zip(row_indices[top_indices], col_indices[top_indices]))\n",
    "\n",
    "        # Printing the result\n",
    "        for idx, original_idx in enumerate(top_original_indices):\n",
    "            print(f\"Node connection: {original_idx[0] + 1, original_idx[1] + 1}, Importance: {feature_importances[top_indices[idx]]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3178cc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for classification, as above, and including stratified k fold validation \n",
    "\n",
    "def classify_oversampled_skf2(data, connections=False, title=None):\n",
    "    triuim1 = np.triu_indices_from(st_matrices[0], k=1)\n",
    "    X = [np.array(matrix)[triuim1] for matrix in data]\n",
    "\n",
    "    # we convert the list of upper triangles to a 2D array\n",
    "    X = np.array(X)\n",
    "    y = np.array(labels)\n",
    "    \n",
    "    # we use SMOTE for oversampling\n",
    "    smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "    # StratifiedKFold with n_splits=5\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    best_params = None\n",
    "\n",
    "    # SVM model\n",
    "    clf = SVC()\n",
    "\n",
    "    # Grid search \n",
    "    param_grid = {\"C\": [0.01, 0.1, 1, 10, 100, 200], \"gamma\": [0.001, 0.01, 0.1, 1, 10]}\n",
    "    grid_search = GridSearchCV(clf, param_grid=param_grid, cv=11)\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    # we use the best hyperparameters for k-fold cross-validation\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # variables to store the best results\n",
    "    best_accuracy = 0.0\n",
    "    best_precision = 0.0\n",
    "    best_recall = 0.0\n",
    "    best_f1 = 0.0\n",
    "    best_confusion_matrix = None\n",
    "\n",
    "    progress_bar = tqdm(total=skf.get_n_splits(X, y), desc=\"Folds\", position=0, leave=True)\n",
    "\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # we apply SMOTE to the training data\n",
    "        X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        X_resampled, y_resampled = shuffle(X_resampled, y_resampled, random_state=42)\n",
    "\n",
    "        # we train the model with the best parameters\n",
    "        best_clf = SVC(C=best_params['C'], gamma=best_params['gamma'])\n",
    "        best_clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "        # Predictions \n",
    "        preds = best_clf.predict(X_test)\n",
    "\n",
    "        # Evaluation\n",
    "        accuracy = accuracy_score(y_test, preds)\n",
    "        precision = precision_score(y_test, preds)\n",
    "        recall = recall_score(y_test, preds)\n",
    "        f1 = f1_score(y_test, preds)\n",
    "        cnf_matrix = confusion_matrix(y_test, preds)\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = round(accuracy, 2)\n",
    "            best_precision = round(precision, 2)\n",
    "            best_recall = round(recall, 2)\n",
    "            best_f1 = round(f1, 2)\n",
    "            best_confusion_matrix = cnf_matrix\n",
    "\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    # Printing the best results\n",
    "    print(\"Best results {}:\".format(title))\n",
    "    print(\"Best Accuracy: {:.4f}\".format(best_accuracy))\n",
    "    print(\"Best Precision: {:.4f}\".format(best_precision))\n",
    "    print(\"Best Recall: {:.4f}\".format(best_recall))\n",
    "    print(\"Best F1 Score: {:.4f}\".format(best_f1))\n",
    "    print(\"Best Confusion Matrix:\")\n",
    "    print(best_confusion_matrix)\n",
    "    print(\"Best Parameters (C and Gamma):\", best_params)\n",
    "    \n",
    "    if connections: \n",
    "        # we apply SMOTE to the data\n",
    "        X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "        X_resampled, y_resampled = shuffle(X_resampled, y_resampled, random_state=42)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.25, random_state=24)\n",
    "\n",
    "        # we train the final model with the best hyperparameters\n",
    "        final_clf = SVC(C=best_params['C'], gamma=best_params['gamma'], kernel='rbf')\n",
    "        final_clf.fit(X_train, y_train)\n",
    "\n",
    "        # Predictions \n",
    "        preds = final_clf.predict(X_test)\n",
    "\n",
    "        # Evaluation\n",
    "        accuracy = accuracy_score(y_test, preds)\n",
    "        precision = precision_score(y_test, preds)\n",
    "        recall = recall_score(y_test, preds)\n",
    "        cnf_matrix = confusion_matrix(y_test, preds)\n",
    "        \n",
    "        n_sv = final_clf.support_vectors_.shape[0]\n",
    "        feature_importances = np.abs(np.dot(final_clf.dual_coef_, final_clf.support_vectors_)).flatten() / n_sv\n",
    "\n",
    "        top_indices = np.argsort(feature_importances)[-7:][::-1]\n",
    "\n",
    "        # row and column indices for the flattened indices\n",
    "        row_indices, col_indices = np.triu_indices(76, k=1)\n",
    "\n",
    "        # we map the flattened indices to the original matrix indices\n",
    "        top_original_indices = list(zip(row_indices[top_indices], col_indices[top_indices]))\n",
    "\n",
    "        # Printing the result\n",
    "        for idx, original_idx in enumerate(top_original_indices):\n",
    "            print(f\"Node connection: {original_idx[0] + 1, original_idx[1] + 1}, Importance: {feature_importances[top_indices[idx]]:.4f}\")\n",
    "\n",
    "\n",
    "    return best_accuracy, best_precision, best_recall, best_f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167e7697",
   "metadata": {},
   "source": [
    "<a id='a5.2'></a>\n",
    "<h2>Connectivity based classification</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15132830",
   "metadata": {},
   "source": [
    "Stratified k-fold validation was introduced late in the analysis process. For archiving purposes, we are including here the results we obtained previous to the use of k-fold validation. Results (only the ones validated with k-fold) will be summarized again on the results section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7dc3fdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|████████████████████████████████| 50/50 [08:08<00:00,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Results:\n",
      "Best Accuracy: 0.9730\n",
      "Best Precision: 0.9487\n",
      "Best Recall: 1.0000\n",
      "Best F1 Score: 0.9737\n",
      "Best Confusion Matrix:\n",
      "[[35  2]\n",
      " [ 0 37]]\n",
      "Best Parameters (C and Gamma): {'C': 1, 'gamma': 0.1}\n",
      "Node connection: (1, 55), Importance: 0.0312\n",
      "Node connection: (12, 43), Importance: 0.0293\n",
      "Node connection: (44, 74), Importance: 0.0274\n",
      "Node connection: (36, 45), Importance: 0.0273\n",
      "Node connection: (31, 43), Importance: 0.0269\n",
      "Node connection: (11, 73), Importance: 0.0245\n",
      "Node connection: (14, 39), Importance: 0.0243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification using structural matrices FA connectivity\n",
    "classify_oversampled(st_matrices, connections=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a139436a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds: 100%|██████████████████████████████████████| 5/5 [00:00<00:00, 28.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best results for structural FA connectivity:\n",
      "Best Accuracy: 1.0000\n",
      "Best Precision: 1.0000\n",
      "Best Recall: 1.0000\n",
      "Best F1 Score: 1.0000\n",
      "Best Confusion Matrix:\n",
      "[[ 3  0]\n",
      " [ 0 30]]\n",
      "Best Parameters (C and Gamma): {'C': 200, 'gamma': 0.001}\n",
      "Node connection: (12, 43), Importance: 3.2681\n",
      "Node connection: (1, 55), Importance: 2.8923\n",
      "Node connection: (44, 74), Importance: 2.5050\n",
      "Node connection: (5, 20), Importance: 2.4635\n",
      "Node connection: (38, 70), Importance: 2.3099\n",
      "Node connection: (28, 45), Importance: 2.0751\n",
      "Node connection: (3, 41), Importance: 1.9891\n"
     ]
    }
   ],
   "source": [
    "# Classification using structural matrices FA connectivity and including stratified k-fold validation\n",
    "a_st, p_st, r_st, f_st = classify_oversampled_skf2(data=st_matrices, connections=True, title=\"for structural FA connectivity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b83d5302",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|████████████████████████████████| 50/50 [09:34<00:00, 11.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Results:\n",
      "Best Accuracy: 1.0000\n",
      "Best Precision: 1.0000\n",
      "Best Recall: 1.0000\n",
      "Best F1 Score: 1.0000\n",
      "Best Confusion Matrix:\n",
      "[[37  0]\n",
      " [ 0 37]]\n",
      "Best Parameters (C and Gamma): {'C': 1, 'gamma': 0.01}\n",
      "Node connection: (7, 43), Importance: 0.0456\n",
      "Node connection: (62, 69), Importance: 0.0426\n",
      "Node connection: (10, 69), Importance: 0.0410\n",
      "Node connection: (20, 61), Importance: 0.0406\n",
      "Node connection: (17, 57), Importance: 0.0401\n",
      "Node connection: (22, 61), Importance: 0.0391\n",
      "Node connection: (17, 69), Importance: 0.0390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification using functional connectivity matrices\n",
    "classify_oversampled(func_matrices, connections=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "082fc12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds: 100%|██████████████████████████████████████| 5/5 [00:00<00:00, 24.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best results for functional connectivity:\n",
      "Best Accuracy: 0.9400\n",
      "Best Precision: 0.9400\n",
      "Best Recall: 1.0000\n",
      "Best F1 Score: 0.9700\n",
      "Best Confusion Matrix:\n",
      "[[ 1  2]\n",
      " [ 0 30]]\n",
      "Best Parameters (C and Gamma): {'C': 100, 'gamma': 0.001}\n",
      "Node connection: (7, 43), Importance: 0.5784\n",
      "Node connection: (5, 38), Importance: 0.4736\n",
      "Node connection: (21, 23), Importance: 0.4631\n",
      "Node connection: (33, 69), Importance: 0.4550\n",
      "Node connection: (20, 61), Importance: 0.4488\n",
      "Node connection: (7, 38), Importance: 0.4390\n",
      "Node connection: (17, 31), Importance: 0.4380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification using functional connectivity matrices and including k-fold validation\n",
    "a_func, p_func, r_func, f_func = classify_oversampled_skf2(data = func_matrices, connections=True,\n",
    "                                    title=\"for functional connectivity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b9ce3242",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|████████████████████████████████| 50/50 [08:54<00:00, 10.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Results:\n",
      "Best Accuracy: 0.9865\n",
      "Best Precision: 0.9737\n",
      "Best Recall: 1.0000\n",
      "Best F1 Score: 0.9867\n",
      "Best Confusion Matrix:\n",
      "[[36  1]\n",
      " [ 0 37]]\n",
      "Best Parameters (C and Gamma): {'C': 1, 'gamma': 0.1}\n",
      "Node connection: (31, 43), Importance: 0.0242\n",
      "Node connection: (7, 43), Importance: 0.0222\n",
      "Node connection: (14, 39), Importance: 0.0217\n",
      "Node connection: (44, 74), Importance: 0.0196\n",
      "Node connection: (45, 64), Importance: 0.0188\n",
      "Node connection: (12, 43), Importance: 0.0172\n",
      "Node connection: (45, 56), Importance: 0.0168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification using functional and structural matrices combined\n",
    "classify_oversampled(all_combined, connections=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "131cc922",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds: 100%|██████████████████████████████████████| 5/5 [00:00<00:00, 22.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best results for weighted combination of matrices:\n",
      "Best Accuracy: 0.9700\n",
      "Best Precision: 0.9700\n",
      "Best Recall: 1.0000\n",
      "Best F1 Score: 0.9800\n",
      "Best Confusion Matrix:\n",
      "[[ 2  1]\n",
      " [ 0 30]]\n",
      "Best Parameters (C and Gamma): {'C': 100, 'gamma': 0.01}\n",
      "Node connection: (31, 43), Importance: 0.2033\n",
      "Node connection: (44, 74), Importance: 0.1716\n",
      "Node connection: (7, 43), Importance: 0.1585\n",
      "Node connection: (1, 69), Importance: 0.1514\n",
      "Node connection: (15, 43), Importance: 0.1445\n",
      "Node connection: (14, 39), Importance: 0.1437\n",
      "Node connection: (12, 43), Importance: 0.1385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification using functional and structural matrices combined and including k-fold validation\n",
    "a_comb, p_comb, r_comb, f_comb = classify_oversampled_skf2(all_combined, connections=True, \n",
    "                                                           title='for weighted combination of matrices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a6749fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix = pd.MultiIndex.from_product([['Connectivity'], ['structural', 'functional', 'combined']])\n",
    "table_connectivity = pd.DataFrame(columns=mix) \n",
    "\n",
    "table_connectivity['statistic'] = ['accuracy', 'precision', 'recall', 'F1']\n",
    "\n",
    "table_connectivity[('Connectivity', 'structural')] = [a_st, p_st, r_st, f_st]\n",
    "table_connectivity[('Connectivity', 'functional')] = [a_func, p_func, r_func, f_func]\n",
    "table_connectivity[('Connectivity', 'combined')] = [a_comb, p_comb, r_comb, f_comb]\n",
    "table_connectivity = table_connectivity.set_index('statistic')\n",
    "table_connectivity.index.name=None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0946f454",
   "metadata": {},
   "source": [
    "<a id='a5.2.1'></a>\n",
    "<h3>Results</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c1a64d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of connectivity based classification:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Connectivity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>structural</th>\n",
       "      <th>functional</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Connectivity                    \n",
       "            structural functional combined\n",
       "accuracy           1.0       0.94     0.97\n",
       "precision          1.0       0.94     0.97\n",
       "recall             1.0       1.00     1.00\n",
       "F1                 1.0       0.97     0.98"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Results of connectivity based classification:\")\n",
    "table_connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aa0949",
   "metadata": {},
   "source": [
    "<a id='a5.3'></a>\n",
    "<h2>Functions for graph based classification</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "072d983d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to classify using graph measures\n",
    "\n",
    "def classify_graph(data, labels):\n",
    "\n",
    "    X = np.array(data)\n",
    "    y = np.array(labels)\n",
    "    \n",
    "    # we use SMOTE for oversampling\n",
    "    smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "    # variables for results\n",
    "    best_accuracy = 0.0\n",
    "    best_precision = 0.0\n",
    "    best_recall = 0.0\n",
    "    best_f1 = 0.0\n",
    "    best_confusion_matrix = None\n",
    "    best_params = None\n",
    "\n",
    "    num_instances = 50\n",
    "\n",
    "    progress_bar = tqdm(total=num_instances, desc=\"Instances\", position=0, leave=True)\n",
    "\n",
    "\n",
    "    for instance in range(num_instances):\n",
    "        \n",
    "        X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "        \n",
    "        X_resampled, y_resampled = shuffle(X_resampled, y_resampled, random_state=42)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.25, random_state=24)\n",
    "\n",
    "        clf = SVC()\n",
    "\n",
    "        # Grid search \n",
    "        param_grid = {\"C\": [0.01, 0.1, 1, 10, 100, 200], \"gamma\": [0.001, 0.01, 0.1, 1, 10]}\n",
    "        grid_search = GridSearchCV(clf, param_grid=param_grid, cv=11)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Train \n",
    "        best_clf = SVC(C=grid_search.best_params_['C'], gamma=grid_search.best_params_['gamma'])\n",
    "        best_clf.fit(X_train, y_train)\n",
    "\n",
    "        # Predictions \n",
    "        preds = best_clf.predict(X_test)\n",
    "\n",
    "        # Evaluation\n",
    "        accuracy = accuracy_score(y_test, preds)\n",
    "        precision = precision_score(y_test, preds)\n",
    "        recall = recall_score(y_test, preds)\n",
    "        f1 = f1_score(y_test, preds)\n",
    "        cnf_matrix = confusion_matrix(y_test, preds)\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_precision = precision\n",
    "            best_recall = recall\n",
    "            best_f1 = f1\n",
    "            best_confusion_matrix = cnf_matrix\n",
    "            best_params = grid_search.best_params_\n",
    "\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    # Printing the best results\n",
    "    print(\"Best Results:\")\n",
    "    print(\"Best Accuracy: {:.4f}\".format(best_accuracy))\n",
    "    print(\"Best Precision: {:.4f}\".format(best_precision))\n",
    "    print(\"Best Recall: {:.4f}\".format(best_recall))\n",
    "    print(\"Best F1 Score: {:.4f}\".format(best_f1))\n",
    "    print(\"Best Confusion Matrix:\")\n",
    "    print(best_confusion_matrix)\n",
    "    print(\"Best Parameters (C and Gamma):\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6e2011a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to classify using graph measures including stratified k-fold validation\n",
    "\n",
    "def classify_graph_skf(data, labels, title=None):\n",
    "    X = np.array(data)\n",
    "    y = np.array(labels)\n",
    "    \n",
    "    # we use SMOTE for oversampling\n",
    "    smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "    # variables to store the best results\n",
    "    best_accuracy = 0.0\n",
    "    best_precision = 0.0\n",
    "    best_recall = 0.0\n",
    "    best_f1 = 0.0\n",
    "    best_confusion_matrix = None\n",
    "    best_params = None\n",
    "\n",
    "    # stratifiedKFold with n_splits=5\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    progress_bar = tqdm(total=skf.get_n_splits(X, y), desc=\"Folds\", position=0, leave=True)\n",
    "\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        X_resampled, y_resampled = shuffle(X_resampled, y_resampled, random_state=42)\n",
    "\n",
    "        clf = SVC()\n",
    "\n",
    "        # Grid search \n",
    "        param_grid = {\"C\": [0.01, 0.1, 1, 10, 100, 200], \"gamma\": [0.001, 0.01, 0.1, 1, 10]}\n",
    "        grid_search = GridSearchCV(clf, param_grid=param_grid, cv=11)\n",
    "        grid_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "        # Train \n",
    "        best_clf = SVC(C=grid_search.best_params_['C'], gamma=grid_search.best_params_['gamma'])\n",
    "        best_clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "        # Predictions\n",
    "        preds = best_clf.predict(X_test)\n",
    "\n",
    "        # Evaluation\n",
    "        accuracy = accuracy_score(y_test, preds)\n",
    "        precision = precision_score(y_test, preds, zero_division=1)\n",
    "        recall = recall_score(y_test, preds)\n",
    "        f1 = f1_score(y_test, preds)\n",
    "        cnf_matrix = confusion_matrix(y_test, preds)\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = round(accuracy, 2)\n",
    "            best_precision = round(precision, 2)\n",
    "            best_recall = round(recall, 2)\n",
    "            best_f1 = round(f1, 2)\n",
    "            best_confusion_matrix = cnf_matrix\n",
    "            best_params = grid_search.best_params_\n",
    "\n",
    "        \n",
    "        progress_bar.update(1)\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    # Printing the best results\n",
    "    print(\"Best Results {}:\".format(title))\n",
    "    print(\"Best Accuracy: {:.4f}\".format(best_accuracy))\n",
    "    print(\"Best Precision: {:.4f}\".format(best_precision))\n",
    "    print(\"Best Recall: {:.4f}\".format(best_recall))\n",
    "    print(\"Best F1 Score: {:.4f}\".format(best_f1))\n",
    "    print(\"Best Confusion Matrix:\")\n",
    "    print(best_confusion_matrix)\n",
    "    print(\"Best Parameters (C and Gamma):\", best_params)\n",
    "    \n",
    "    return best_accuracy, best_precision, best_recall, best_f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff545dd",
   "metadata": {},
   "source": [
    "<a id='a5.4'></a>\n",
    "<h2>Classification using global graph measures</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d779f05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We generate labels \n",
    "\n",
    "zeros = [0] * 147\n",
    "ones = [1] * 18\n",
    "\n",
    "concat_labels = zeros + ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1e015366",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_strength_ms_nodes = calculate_graph_measures(ms_st)\n",
    "global_strength_hv_nodes = calculate_graph_measures(hv_st)\n",
    "global_strength_list = [list(i.values()) for i in global_strength_ms_nodes] + [list(i.values()) for i in global_strength_hv_nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "11a28433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(global_strength_hv_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "cee3c6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|████████████████████████████████| 50/50 [00:51<00:00,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Results:\n",
      "Best Accuracy: 0.9865\n",
      "Best Precision: 0.9737\n",
      "Best Recall: 1.0000\n",
      "Best F1 Score: 0.9867\n",
      "Best Confusion Matrix:\n",
      "[[36  1]\n",
      " [ 0 37]]\n",
      "Best Parameters (C and Gamma): {'C': 10, 'gamma': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classify_graph(data=global_strength_list, labels=concat_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d148d7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds: 100%|██████████████████████████████████████| 5/5 [00:05<00:00,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Results using global strength:\n",
      "Best Accuracy: 0.9700\n",
      "Best Precision: 0.7500\n",
      "Best Recall: 1.0000\n",
      "Best F1 Score: 0.8600\n",
      "Best Confusion Matrix:\n",
      "[[29  1]\n",
      " [ 0  3]]\n",
      "Best Parameters (C and Gamma): {'C': 10, 'gamma': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "a_str, p_str, r_str, f1_str = classify_graph_skf(data=global_strength_list, \n",
    "                               labels=concat_labels, title='using global strength')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ac2ad9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the rich club measures obtained from functional matrices for another classification task\n",
    "\n",
    "global_rich_ms_nodes = calculate_graph_measures(ms_func, measure='rich_club')\n",
    "global_rich_hv_nodes = calculate_graph_measures(hv_func, measure='rich_club')\n",
    "global_rich_data = [mean(i) for i in global_rich_ms_nodes] + [mean(i) for i in global_rich_hv_nodes]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c7138c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_rich_data_l = [[i] for i in global_rich_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a7a05799",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|████████████████████████████████| 50/50 [00:44<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Results:\n",
      "Best Accuracy: 0.7703\n",
      "Best Precision: 0.8333\n",
      "Best Recall: 0.6757\n",
      "Best F1 Score: 0.7463\n",
      "Best Confusion Matrix:\n",
      "[[32  5]\n",
      " [12 25]]\n",
      "Best Parameters (C and Gamma): {'C': 100, 'gamma': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classify_graph(data=global_rich_data_l, labels=concat_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "dac4acee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds: 100%|██████████████████████████████████████| 5/5 [00:04<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Results using rich club measure:\n",
      "Best Accuracy: 0.9400\n",
      "Best Precision: 0.6700\n",
      "Best Recall: 0.6700\n",
      "Best F1 Score: 0.6700\n",
      "Best Confusion Matrix:\n",
      "[[29  1]\n",
      " [ 1  2]]\n",
      "Best Parameters (C and Gamma): {'C': 200, 'gamma': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "a_ri, p_ri, r_ri, f1_ri = classify_graph_skf(data=global_rich_data_l, \n",
    "                                             labels=concat_labels, title='using rich club measure')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d60d2d",
   "metadata": {},
   "source": [
    "<a id='a5.5'></a>\n",
    "<h2>Classification using vectors of diverse nodal graph measures</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceaa5f6",
   "metadata": {},
   "source": [
    "In the following cells, we take all the nodal graph measures that have obtained significant differences between patients and controls, and for each patient and control we concatenate the values of only the significant nodes to create a vector. So, each patient is characterized by a vector of values representing different nodal graph measures. We use these vectors to classify patients and controls, obtaining a high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "055a4877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the vector that gathers the different graph nodal measures\n",
    "\n",
    "ms_strength_nodes = np.transpose(significant_nodes_ms_strength).tolist()\n",
    "hv_strength_nodes = np.transpose(significant_nodes_hv_strength).tolist()\n",
    "\n",
    "ms_degree_centrality_nodes = np.transpose(significant_nodes_ms_dc).tolist()\n",
    "hv_degree_centrality_nodes = np.transpose(significant_nodes_hv_dc).tolist()\n",
    "\n",
    "ms_degree_centrality_nodes_func = np.transpose(significant_nodes_ms_dc_func).tolist()\n",
    "hv_degree_centrality_nodes_func = np.transpose(significant_nodes_hv_dc_func).tolist()\n",
    "\n",
    "ms_closeness_centrality_nodes = np.transpose(significant_nodes_ms_cc).tolist()\n",
    "hv_closeness_centrality_nodes = np.transpose(significant_nodes_hv_cc).tolist()\n",
    "\n",
    "ms_closeness_centrality_nodes_func = np.transpose(significant_nodes_ms_cc_func).tolist()\n",
    "hv_closeness_centrality_nodes_func = np.transpose(significant_nodes_hv_cc_func).tolist()\n",
    "\n",
    "ms_clustering_coefficient_nodes_func = np.transpose(significant_nodes_ms_cluster_func).tolist()\n",
    "hv_clustering_coefficient_nodes_func = np.transpose(significant_nodes_hv_cluster_func).tolist()\n",
    "\n",
    "ms_betweenness_centrality_nodes = np.transpose(significant_nodes_ms_bc).tolist()\n",
    "hv_betweenness_centrality_nodes = np.transpose(significant_nodes_hv_bc).tolist()\n",
    "\n",
    "ms_betweenness_centrality_nodes_func = np.transpose(significant_nodes_ms_bc_func).tolist()\n",
    "hv_betweenness_centrality_nodes_func = np.transpose(significant_nodes_hv_bc_func).tolist()\n",
    "\n",
    "ms_eigenvector_centrality_nodes = np.transpose(significant_nodes_ms_ec).tolist()\n",
    "hv_eigenvector_centrality_nodes = np.transpose(significant_nodes_hv_ec).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "17ebf358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "ms_nodes = [a + b + c + d + e + f + g + h + i  for a, b, c, d, e, f, g, h, i in zip(ms_strength_nodes, \n",
    "ms_degree_centrality_nodes, ms_degree_centrality_nodes_func, ms_closeness_centrality_nodes, \n",
    "ms_closeness_centrality_nodes_func, ms_clustering_coefficient_nodes_func, ms_betweenness_centrality_nodes, \n",
    "ms_betweenness_centrality_nodes_func, ms_eigenvector_centrality_nodes)]\n",
    "print(len(ms_nodes))\n",
    "\n",
    "hv_nodes = [a + b + c + d + e + f + g + h + i  for a, b, c, d, e, f, g, h, i in zip(hv_strength_nodes, \n",
    "hv_degree_centrality_nodes, hv_degree_centrality_nodes_func, hv_closeness_centrality_nodes, \n",
    "hv_closeness_centrality_nodes_func, hv_clustering_coefficient_nodes_func, hv_betweenness_centrality_nodes, \n",
    "hv_betweenness_centrality_nodes_func, hv_eigenvector_centrality_nodes)]\n",
    "print(len(hv_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1eeb28fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodal_graph_data = ms_nodes + hv_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8488ed7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|████████████████████████████████| 50/50 [00:52<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Results:\n",
      "Best Accuracy: 0.9730\n",
      "Best Precision: 0.9487\n",
      "Best Recall: 1.0000\n",
      "Best F1 Score: 0.9737\n",
      "Best Confusion Matrix:\n",
      "[[35  2]\n",
      " [ 0 37]]\n",
      "Best Parameters (C and Gamma): {'C': 10, 'gamma': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classify_graph(data=nodal_graph_data, labels=concat_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6df30a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds: 100%|██████████████████████████████████████| 5/5 [00:05<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Results using vector of mixed nodal measures:\n",
      "Best Accuracy: 0.9700\n",
      "Best Precision: 0.7500\n",
      "Best Recall: 1.0000\n",
      "Best F1 Score: 0.8600\n",
      "Best Confusion Matrix:\n",
      "[[29  1]\n",
      " [ 0  3]]\n",
      "Best Parameters (C and Gamma): {'C': 10, 'gamma': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "a_n, p_n, r_n, f1_n = classify_graph_skf(data=nodal_graph_data, \n",
    "                   labels=concat_labels, title='using vector of mixed nodal measures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "92e9d4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_graph = pd.MultiIndex.from_product([['Graph'], [\"structural strength\", 'functional rich club', \n",
    "                                                    'vector of node measures']])\n",
    "table_graph = pd.DataFrame(columns=mix_graph) \n",
    "\n",
    "table_graph['statistic'] = ['accuracy', 'precision', 'recall', 'F1']\n",
    "table_graph[('Graph', \"structural strength\")] = [a_str, p_str, r_str, f1_str]\n",
    "table_graph[('Graph', 'functional rich club')] = [a_ri, p_ri, r_ri, f1_ri]\n",
    "table_graph[('Graph', 'vector of node measures')] = [a_n, p_n, r_n, f1_n]\n",
    "table_graph = table_graph.set_index('statistic')\n",
    "table_graph.index.name=None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c0eb59",
   "metadata": {},
   "source": [
    "<a id='a5.5.1'></a>\n",
    "<h3>Results</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f54fadce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Graph</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>structural strength</th>\n",
       "      <th>functional rich club</th>\n",
       "      <th>vector of node measures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Graph                                             \n",
       "          structural strength functional rich club vector of node measures\n",
       "accuracy                 0.97                 0.94                    0.97\n",
       "precision                0.75                 0.67                    0.75\n",
       "recall                   1.00                 0.67                    1.00\n",
       "F1                       0.86                 0.67                    0.86"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c583e9c",
   "metadata": {},
   "source": [
    "<a id='a5.6'></a>\n",
    "<h2>Classification using brain volumes</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92a80e4",
   "metadata": {},
   "source": [
    "<a id='a5.6.1'></a>\n",
    "<h3>All brain volumes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ef0e07a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "40960\n",
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# We normalize volumes from 0 to 1\n",
    "\n",
    "flattened_list = [item for sublist in volumes for item in sublist]\n",
    "\n",
    "global_min = min(flattened_list)\n",
    "global_max = max(flattened_list)\n",
    "\n",
    "print(global_min)\n",
    "print(global_max)\n",
    "\n",
    "normalized_list = [(x - global_min) / (global_max - global_min) for x in flattened_list]\n",
    "\n",
    "num_elements = len(volumes[0])\n",
    "normalized_volumes = [normalized_list[i:i + num_elements] for i in range(0, len(normalized_list), num_elements)]\n",
    "\n",
    "print(min([min(i) for i in normalized_volumes]))\n",
    "print(max([max(i) for i in normalized_volumes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "56b01319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "normalized_v_ms = normalized_volumes[:147]\n",
    "normalized_v_hv = normalized_volumes[147:]\n",
    "print(len(normalized_v_ms))\n",
    "print(len(normalized_v_hv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "282769b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: -3.678241051937038\n",
      "P-value: 0.00023583029405776083\n"
     ]
    }
   ],
   "source": [
    "# we perform a t-test for independence between patients and controls\n",
    "\n",
    "flat_list1 = [item for sublist in normalized_v_ms for item in sublist]\n",
    "flat_list2 = [item for sublist in normalized_v_hv for item in sublist]\n",
    "\n",
    "# Perform t-test\n",
    "t_statistic, p_value = ttest_ind(np.array(flat_list1), np.array(flat_list2))\n",
    "\n",
    "# Print the results\n",
    "print(f'T-statistic: {t_statistic}')\n",
    "print(f'P-value: {p_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5a96d8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|████████████████████████████████| 50/50 [00:48<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Results:\n",
      "Best Accuracy: 0.9459\n",
      "Best Precision: 0.9024\n",
      "Best Recall: 1.0000\n",
      "Best F1 Score: 0.9487\n",
      "Best Confusion Matrix:\n",
      "[[33  4]\n",
      " [ 0 37]]\n",
      "Best Parameters (C and Gamma): {'C': 100, 'gamma': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classify_graph(data=normalized_volumes, labels=concat_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "cd9be31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds: 100%|██████████████████████████████████████| 5/5 [00:05<00:00,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Results using brain volumes:\n",
      "Best Accuracy: 0.9400\n",
      "Best Precision: 1.0000\n",
      "Best Recall: 0.5000\n",
      "Best F1 Score: 0.6700\n",
      "Best Confusion Matrix:\n",
      "[[29  0]\n",
      " [ 2  2]]\n",
      "Best Parameters (C and Gamma): {'C': 100, 'gamma': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "a_vol, p_vol, r_vol, f1_vol = classify_graph_skf(data=normalized_volumes, \n",
    "                                                 labels=concat_labels, title='using brain volumes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6690bb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: 1.7383999340396554\n",
      "P-value: 0.08216792305578006\n"
     ]
    }
   ],
   "source": [
    "# Test for independence of groups between rrms and pp/spms based on volumes\n",
    "\n",
    "\n",
    "volumes_ms_rr = [normalized_v_ms[i] for i, value in enumerate(ms_type_labels) if value == 0]\n",
    "volumes_ms_psp = [normalized_v_ms[i] for i, value in enumerate(ms_type_labels) if value == 1]\n",
    "\n",
    "flat_list_rr = [item for sublist in volumes_ms_rr for item in sublist]\n",
    "flat_list_psp = [item for sublist in volumes_ms_psp for item in sublist]\n",
    "\n",
    "# Perform t-test\n",
    "t_statistic_phe, p_value_phe = ttest_ind(np.array(flat_list_rr), np.array(flat_list_psp))\n",
    "\n",
    "# Print the results\n",
    "print(f'T-statistic: {t_statistic_phe}')\n",
    "print(f'P-value: {p_value_phe}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601bf874",
   "metadata": {},
   "source": [
    "<a id='a5.6.2'></a>\n",
    "<h3>Thalamic volumes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "12d5bf4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>32</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7464</td>\n",
       "      <td>6720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9480</td>\n",
       "      <td>9208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8912</td>\n",
       "      <td>8936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8728</td>\n",
       "      <td>8600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8784</td>\n",
       "      <td>8552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>8088</td>\n",
       "      <td>7456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6968</td>\n",
       "      <td>6392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>8664</td>\n",
       "      <td>8696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>7744</td>\n",
       "      <td>7064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>7048</td>\n",
       "      <td>6512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       32    39\n",
       "0    7464  6720\n",
       "1    9480  9208\n",
       "2    8912  8936\n",
       "3    8728  8600\n",
       "4    8784  8552\n",
       "..    ...   ...\n",
       "142  8088  7456\n",
       "143  6968  6392\n",
       "144  8664  8696\n",
       "145  7744  7064\n",
       "146  7048  6512\n",
       "\n",
       "[147 rows x 2 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we subset the values for left and right Thalamus\n",
    "\n",
    "thalamic_volumes_ms = volumes_patients[['32', '39']]\n",
    "thalamic_volumes_hv = volumes_controls[['32', '39']]\n",
    "thalamic_volumes_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3864c981",
   "metadata": {},
   "outputs": [],
   "source": [
    "th_ms = thalamic_volumes_ms.values[:,0:].tolist()\n",
    "th_hv = thalamic_volumes_hv.values[:,0:].tolist()\n",
    "thal = th_ms + th_hv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "68b473a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376\n",
      "10344\n",
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# we normalize values\n",
    "\n",
    "flattened_list_t = [item for sublist in thal for item in sublist]\n",
    "\n",
    "# Find the global min and max values\n",
    "global_min_t = min(flattened_list_t)\n",
    "global_max_t = max(flattened_list_t)\n",
    "\n",
    "print(global_min_t)\n",
    "print(global_max_t)\n",
    "\n",
    "normalized_list_t = [(x - global_min_t) / (global_max_t - global_min_t) for x in flattened_list_t]\n",
    "\n",
    "num_elements_t = len(th_ms[0])\n",
    "normalized_volumes_t = [normalized_list_t[i:i + num_elements_t] for i in range(0, len(normalized_list_t), num_elements_t)]\n",
    "\n",
    "print(max([max(i) for i in normalized_volumes_t]))\n",
    "print(min([min(i) for i in normalized_volumes_t]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2b59c3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "normalized_th_ms = normalized_volumes_t[:147]\n",
    "normalized_th_hv = normalized_volumes_t[147:]\n",
    "print(len(normalized_th_ms))\n",
    "print(len(normalized_th_hv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "45d52261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: -5.228102807167816\n",
      "P-value: 3.0559398745953023e-07\n"
     ]
    }
   ],
   "source": [
    "# we perform a t-test for independence between patients and controls \n",
    "\n",
    "flat_list1t = [item for sublist in normalized_th_ms for item in sublist]\n",
    "flat_list2t = [item for sublist in normalized_th_hv for item in sublist]\n",
    "\n",
    "# Perform t-test\n",
    "t_statistic_t, p_value_t = ttest_ind(np.array(flat_list1t), np.array(flat_list2t))\n",
    "\n",
    "# Print the results\n",
    "print(f'T-statistic: {t_statistic_t}')\n",
    "print(f'P-value: {p_value_t}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "603a1d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: 1.6785661595692423\n",
      "P-value: 0.09430642250575426\n"
     ]
    }
   ],
   "source": [
    "# we perform a t-test for independence between phenotype groups\n",
    "\n",
    "volumes_ms_rr_t = [normalized_th_ms[i] for i, value in enumerate(ms_type_labels) if value == 0]\n",
    "volumes_ms_psp_t = [normalized_th_ms[i] for i, value in enumerate(ms_type_labels) if value == 1]\n",
    "\n",
    "flat_list_rr_t = [item for sublist in volumes_ms_rr_t for item in sublist]\n",
    "flat_list_psp_t = [item for sublist in volumes_ms_psp_t for item in sublist]\n",
    "\n",
    "# Perform t-test\n",
    "t_statistic_phe_t, p_value_phe_t = ttest_ind(np.array(flat_list_rr_t), np.array(flat_list_psp_t))\n",
    "\n",
    "# Print the results\n",
    "print(f'T-statistic: {t_statistic_phe_t}')\n",
    "print(f'P-value: {p_value_phe_t}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0b571f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds: 100%|██████████████████████████████████████| 5/5 [00:04<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Results using only thalamic volumes:\n",
      "Best Accuracy: 0.6700\n",
      "Best Precision: 0.1000\n",
      "Best Recall: 0.3300\n",
      "Best F1 Score: 0.1500\n",
      "Best Confusion Matrix:\n",
      "[[21  9]\n",
      " [ 2  1]]\n",
      "Best Parameters (C and Gamma): {'C': 200, 'gamma': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "a_th, p_th, r_th, f1_th = classify_graph_skf(data=normalized_volumes_t, \n",
    "                                             labels=concat_labels, title='using only thalamic volumes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9626d8b6",
   "metadata": {},
   "source": [
    "<a id='a5.6.3'></a>\n",
    "<h3>Classification using the 5 nodes with the biggest difference in volumes between patients and controls</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ee2b1d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We subtract volumes to identify the 5 nodes with the biggest difference between groups\n",
    "array1 = np.array(normalized_v_ms)\n",
    "array2 = np.array(normalized_v_hv)\n",
    "\n",
    "mean_vol_ms = np.mean(array1, axis=0)\n",
    "mean_vol_hv = np.mean(array2, axis=0)\n",
    "\n",
    "vol_difference = list(np.subtract(mean_vol_hv, mean_vol_ms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8a7af7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[71, 26, 22, 73, 67]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_indices = np.argsort(vol_difference)[::-1]\n",
    "top_5_indices = sorted_indices[:5]\n",
    "top_5_nodes = [index + 1 for index in top_5_indices]\n",
    "top_5_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "46d54450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(71, 'ctx-rh-superiorfrontal'), (26, 'ctx-lh-superiorfrontal'), (22, 'ctx-lh-precentral'), (73, 'ctx-rh-superiortemporal'), (67, 'ctx-rh-precentral')]\n"
     ]
    }
   ],
   "source": [
    "# We show the names of the identified nodes\n",
    "corresponding_names = [(index, nodes_dict.get(index)) for index in top_5_nodes]\n",
    "print(corresponding_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "48a7322c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>71</th>\n",
       "      <th>26</th>\n",
       "      <th>22</th>\n",
       "      <th>73</th>\n",
       "      <th>67</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31088</td>\n",
       "      <td>26560</td>\n",
       "      <td>15312</td>\n",
       "      <td>16560</td>\n",
       "      <td>13696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34160</td>\n",
       "      <td>29336</td>\n",
       "      <td>16544</td>\n",
       "      <td>19168</td>\n",
       "      <td>16176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29896</td>\n",
       "      <td>24512</td>\n",
       "      <td>15504</td>\n",
       "      <td>18824</td>\n",
       "      <td>13696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33904</td>\n",
       "      <td>27808</td>\n",
       "      <td>17816</td>\n",
       "      <td>21024</td>\n",
       "      <td>16216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35600</td>\n",
       "      <td>30088</td>\n",
       "      <td>15584</td>\n",
       "      <td>21200</td>\n",
       "      <td>14696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>34304</td>\n",
       "      <td>30856</td>\n",
       "      <td>15112</td>\n",
       "      <td>18112</td>\n",
       "      <td>13632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>30408</td>\n",
       "      <td>26576</td>\n",
       "      <td>12800</td>\n",
       "      <td>16376</td>\n",
       "      <td>11784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>39072</td>\n",
       "      <td>30384</td>\n",
       "      <td>16384</td>\n",
       "      <td>20936</td>\n",
       "      <td>16016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>38984</td>\n",
       "      <td>33160</td>\n",
       "      <td>16496</td>\n",
       "      <td>20208</td>\n",
       "      <td>15312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>28152</td>\n",
       "      <td>22952</td>\n",
       "      <td>11144</td>\n",
       "      <td>13184</td>\n",
       "      <td>11792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        71     26     22     73     67\n",
       "0    31088  26560  15312  16560  13696\n",
       "1    34160  29336  16544  19168  16176\n",
       "2    29896  24512  15504  18824  13696\n",
       "3    33904  27808  17816  21024  16216\n",
       "4    35600  30088  15584  21200  14696\n",
       "..     ...    ...    ...    ...    ...\n",
       "142  34304  30856  15112  18112  13632\n",
       "143  30408  26576  12800  16376  11784\n",
       "144  39072  30384  16384  20936  16016\n",
       "145  38984  33160  16496  20208  15312\n",
       "146  28152  22952  11144  13184  11792\n",
       "\n",
       "[147 rows x 5 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_volumes_ms = volumes_patients[[str(v) for v in top_5_nodes]]\n",
    "top_volumes_hv = volumes_controls[[str(v) for v in top_5_nodes]]\n",
    "top_volumes_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "35f80473",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_volumes = [[sublist[i] for i in top_5_indices] for sublist in normalized_volumes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "33d3c428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "normalized_top5_ms = top_volumes[:147]\n",
    "normalized_top5_hv = top_volumes[147:]\n",
    "print(len(normalized_top5_ms))\n",
    "print(len(normalized_top5_hv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3fe5196c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: -2.5644489898671288\n",
      "P-value: 0.0105103277181547\n"
     ]
    }
   ],
   "source": [
    "# We perform a t-test for independence between groups using the top 5 most different volumes\n",
    "\n",
    "flat_listtop5_1 = [item for sublist in normalized_top5_ms for item in sublist]\n",
    "flat_listtop5_2 = [item for sublist in normalized_top5_hv for item in sublist]\n",
    "\n",
    "# Perform t-test\n",
    "t_statistic_top5, p_value_top5 = ttest_ind(np.array(flat_listtop5_1), np.array(flat_listtop5_2))\n",
    "\n",
    "# Print the results\n",
    "print(f'T-statistic: {t_statistic_top5}')\n",
    "print(f'P-value: {p_value_top5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d73a9982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds: 100%|██████████████████████████████████████| 5/5 [00:04<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Results using the volumes of the 5 most different nodes:\n",
      "Best Accuracy: 0.7600\n",
      "Best Precision: 0.1400\n",
      "Best Recall: 0.3300\n",
      "Best F1 Score: 0.2000\n",
      "Best Confusion Matrix:\n",
      "[[24  6]\n",
      " [ 2  1]]\n",
      "Best Parameters (C and Gamma): {'C': 100, 'gamma': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "a_5, p_5, r_5, f1_5 = classify_graph_skf(data=top_volumes, \n",
    "                   labels=concat_labels, title='using the volumes of the 5 most different nodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "49d08798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: 1.027696517874914\n",
      "P-value: 0.3044316103444145\n"
     ]
    }
   ],
   "source": [
    "# we check for independence between phenotype groups\n",
    "\n",
    "volumes_ms_rr_top5 = [normalized_top5_ms[i] for i, value in enumerate(ms_type_labels) if value == 0]\n",
    "volumes_ms_psp_top5 = [normalized_top5_ms[i] for i, value in enumerate(ms_type_labels) if value == 1]\n",
    "\n",
    "flat_list_rr_top5 = [item for sublist in volumes_ms_rr_top5 for item in sublist]\n",
    "flat_list_psp_top5 = [item for sublist in volumes_ms_psp_top5 for item in sublist]\n",
    "\n",
    "# Perform t-test\n",
    "t_statistic_phe_top5, p_value_phe_top5 = ttest_ind(np.array(flat_list_rr_top5), np.array(flat_list_psp_top5))\n",
    "\n",
    "# Print the results\n",
    "print(f'T-statistic: {t_statistic_phe_top5}')\n",
    "print(f'P-value: {p_value_phe_top5}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e643d531",
   "metadata": {},
   "source": [
    "<a id='a5.6.4'></a>\n",
    "<h3>Results</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c2e06907",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_graph_vol= pd.MultiIndex.from_product([['Brain volumes'], ['all', 'thalamic', \n",
    "                                                    '5 most different']])\n",
    "table_vol = pd.DataFrame(columns=mix_graph_vol) \n",
    "\n",
    "table_vol['statistic'] = ['accuracy', 'precision', 'recall', 'F1']\n",
    "table_vol[('Brain volumes', 'all')] = [a_vol, p_vol, r_vol, f1_vol]\n",
    "table_vol[('Brain volumes', 'thalamic')] = [a_th, p_th, r_th, f1_th]\n",
    "table_vol[('Brain volumes', '5 most different')] = [a_5, p_5, r_5, f1_5]\n",
    "table_vol = table_vol.set_index('statistic')\n",
    "table_vol.index.name=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2691c490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Brain volumes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>thalamic</th>\n",
       "      <th>5 most different</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Brain volumes                          \n",
       "                    all thalamic 5 most different\n",
       "accuracy           0.94     0.67             0.76\n",
       "precision          1.00     0.10             0.14\n",
       "recall             0.50     0.33             0.33\n",
       "F1                 0.67     0.15             0.20"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_vol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2a4fea",
   "metadata": {},
   "source": [
    "<a id='a5.7'></a>\n",
    "<h2>Summary of classification results</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4d3c953e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Connectivity</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Graph</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Brain volumes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>structural</th>\n",
       "      <th>functional</th>\n",
       "      <th>combined</th>\n",
       "      <th>structural strength</th>\n",
       "      <th>functional rich club</th>\n",
       "      <th>vector of node measures</th>\n",
       "      <th>all</th>\n",
       "      <th>thalamic</th>\n",
       "      <th>5 most different</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Connectivity                                   Graph  \\\n",
       "            structural functional combined structural strength   \n",
       "accuracy           1.0       0.94     0.97                0.97   \n",
       "precision          1.0       0.94     0.97                0.75   \n",
       "recall             1.0       1.00     1.00                1.00   \n",
       "F1                 1.0       0.97     0.98                0.86   \n",
       "\n",
       "                                                       Brain volumes           \\\n",
       "          functional rich club vector of node measures           all thalamic   \n",
       "accuracy                  0.94                    0.97          0.94     0.67   \n",
       "precision                 0.67                    0.75          1.00     0.10   \n",
       "recall                    0.67                    1.00          0.50     0.33   \n",
       "F1                        0.67                    0.86          0.67     0.15   \n",
       "\n",
       "                            \n",
       "          5 most different  \n",
       "accuracy              0.76  \n",
       "precision             0.14  \n",
       "recall                0.33  \n",
       "F1                    0.20  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_class = pd.concat([table_connectivity, table_graph, table_vol], axis=1)\n",
    "summary_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6431104e",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0455f3",
   "metadata": {},
   "source": [
    "<a id='a6'></a>\n",
    "<h1>Comparison of strength for connectogram visualization</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddd056e",
   "metadata": {},
   "source": [
    "In these last cells we will export the the differences in strength between patients and controls for visualization purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3456da4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We subset the nodes where we obtained a significant difference in nodal strength\n",
    "\n",
    "ms_strength_nodes = np.transpose(significant_nodes_ms_strength).tolist()\n",
    "hv_strength_nodes = np.transpose(significant_nodes_hv_strength).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d5b8c489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of significant nodes: 54/76\n",
      "List of significant nodes: [2, 3, 4, 5, 6, 8, 9, 10, 11, 13, 14, 15, 17, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 32, 33, 36, 38, 39, 40, 43, 44, 45, 47, 48, 51, 53, 54, 55, 56, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74]\n",
      "Test used: mann-whitney\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vant/anaconda3/envs/svm/lib/python3.11/site-packages/scipy/stats/_morestats.py:1882: UserWarning: p-value may not be accurate for N > 5000.\n",
      "  warnings.warn(\"p-value may not be accurate for N > 5000.\")\n"
     ]
    }
   ],
   "source": [
    "significant_nodes_ms_strength, significant_nodes_hv_strength, node_list = stats_nodal_test(ms_st, hv_st, verbose=False, sn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e196f557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We subtract differences between controls and patients, and we export the data as a file,\n",
    "# containing the list of 54 nodes where we found significant differences, and their values \n",
    "\n",
    "ms_strength_array = np.array(ms_strength_nodes)\n",
    "average_strenght_nodes_ms = np.mean(ms_strength_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "926696df",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv_strength_array = np.array(hv_strength_nodes)\n",
    "average_strenght_nodes_hv = np.mean(hv_strength_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "8c28fe7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1738492929338413, 2.0646539783425943, 0.9399113853953045, 1.9256643787616294, 2.2205081946261487, 2.176947737388506, 2.5701400944308013, 1.7009351330681035, 2.4373601113541525, 1.9834546568647369, 1.2877271411019056, 1.7847869484231556, 1.1341160881280494, 2.116120919989134, 2.298275747910388, 1.3605665572515129, 1.2420825748303166, 2.637478776938579, 1.2710064404205035, 1.7795681745536314, 2.774998752293275, 1.8935526337900583, 2.259448633800531, 1.5886548802273026, 1.0514206089430616, 3.088031095461824, 1.3080498589655623, 1.5674358752353363, 2.080312756986679, 2.9421166878741083, 0.8671094625240068, 1.7062176656812387, 1.3307830921273514, 2.584403988948919, 2.3564939043933606, 2.054779239191717, 2.814316623286409, 1.6101526461938036, 2.3802871630316194, 2.2336891514567796, 1.4537105672049755, 1.4311224236764915, 1.5763673927580957, 1.1213451245930486, 2.3517597497661207, 1.5955297792617777, 0.9172149791030186, 1.260230785848421, 2.3135822965991792, 1.903825948560474, 1.9519656637395038, 2.6810933037995213, 2.0578021041763677, 1.8903520762126576]\n"
     ]
    }
   ],
   "source": [
    "strenght_substract = average_strenght_nodes_hv - average_strenght_nodes_ms\n",
    "strength_difference = strenght_substract.tolist()\n",
    "print(strength_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1ab75bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "strength_dict = dict(zip(node_list, strength_difference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "58cf02ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file_name = 'nodal_strengths.pkl'\n",
    "\n",
    "with open(file_name, 'wb') as file:\n",
    "    pickle.dump(strength_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca0ce69",
   "metadata": {},
   "source": [
    "<a id='a7'></a>\n",
    "<h1>Preliminary conclusions</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f674d2",
   "metadata": {},
   "source": [
    "Statistical tests have confirmed sgnificant differences between patients and controls when using connectivity matrices, graph measures and brain volume measures. We haven't been able to find significant differences between phenotype groups, and thus we have restricted our classification tasks to discerning between patients and controls. We have obtained the highest accuracy of classification when using structural FA connectivity, though functional and combined matrices have also yielded high accuracy (we combined functional and structural matrices through a simple weighted sum procedure, giving 75% importance to structural connectivity). Concerning global graph measures, we only obtain statistically significant differences between groups using network global strength of structural matrices. Remarkably, rich club measure of functional connectivity also yields significant difference between groups, though the precision it delivers in SVM classification tasks is sensibly lower compared to strength. On the other hand, nodal graph measures reveal significant differences on different amounts of nodes accross different types of measure. We used that fact to create a heterogeneous vector, formed by an ordered mixture of nodal graph measures derived from both structural and fucntional connectivity, to describe each subject, and we used these vectors in an SVM classification task, obtaining high levels of accuracy. Finally, we explored the capacity of brain volume data to discern between patents and controls, this investigating the role of brain atrophy in MS. We characterized subjects using three different aggregations of data: their complete brain volume information, the volumes of only thalamic nodes, and the 5 nodes where the volume difference is bigger, obtaining different results that we gather in our result summary table in section 6. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "svm",
   "language": "python",
   "name": "svm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
